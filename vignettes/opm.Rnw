\documentclass[nojss]{jss}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% GENERAL HINTS: STYLE OF THIS DOCUMENT
%
% Use \pkg{} for package names.
% Use \proglang{} for classes.
% Use \code{} for R commands.
% Use `` and '' for opening and closing double quotes, respectively.
% Put a single sentence in a single line, i.e. start a new line for each new sentence.
% Use empty lines for indicating paragraphs.
% Put several empty lines before the start of a new section.
% Put several empty lines surrounding a figure caption.
% Put words such as "via" in italics.
% Put taxon names in italics (but not strain names).
% Put TODOs in \rcsmark or \rcscom tags and remove them once done.
% Be concise and avoid repetitions, as they cause a huge maintenance problem.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Add Revision Control System (RCS) Markups
\usepackage{ulem}      % use this for sout
\normalem              % set \emph to \textit again
% Additions (in blue)
\def\rcsadd#1{{\color{blue}#1}}
% Deletions (in red)
\def\rcsdel#1{{\color{red}\sout{#1}}}
% Yellow box (few words)
\def\rcsmark#1{\colorbox{yellow}{#1}}
%Yellow box (paragraph)
\def\rcscom#1{\noindent\newline\vspace*{0.5cm}\colorbox{yellow}{\parbox{\textwidth}{#1}}\vspace*{0.5cm}}

%% needed for CRAN checking
%\VignetteIndexEntry{Using opm}

% authors, first page
\author{Lea A.I. Vaas\\Leibniz Institute DSMZ \And
        Johannes Sikorski\\Leibniz Institute DSMZ  \AND
        Benjamin Hofner\\Universit\"{a}t Erlangen-N\"{u}rnberg \And
        Nora Buddruhs\\Leibniz Institute DSMZ \And
        Anne Fiebig\\Leibniz Institute DSMZ \AND
        Hans-Peter Klenk\\Leibniz Institute DSMZ \And
        Markus G\"{o}ker\\Leibniz Institute DSMZ}

% title, first page
\title{\pkg{opm}: An R Package for Analysing OmniLog\textregistered \ Phenotype MicroArray Data}

% authors, header on every 2nd page
\Plainauthor{L.A.I. Vaas, J. Sikorski, B. Hofner, N. Buddruhs, A. Fiebig, H.-P. Klenk, M. G\"{o}ker}

% main title, first page
\Plaintitle{opm: An R package for analysing OmniLog\textregistered \ Phenotype MicroArray Data}

% short title, header on every 2nd page
\Shorttitle{Phenotype MicroArray Data}

\Abstract{
The OmniLog\textregistered \ Phenotype Microarray system is able to monitor simultaneously, on a longitudinal time scale, the phenotypic reaction of single-celled organisms such as bacteria, fungi, and animal cell cultures to up to 2,000 environmental challenges spotted on sets of 96-well microtiter plates.
The phenotypic reactions are recorded as respiration kinetics with a shape comparable to growth curves.
Tools for storing the curve kinetics, aggregating the curve parameters, recording associated metadata of organisms and experimental settings as well as methods for analysing graphically and statistically these highly complex data sets are increasingly in demand.

The \pkg{opm} \proglang{R} package facilitates management, visualization and statistical analysis of Phenotype Microarray data.
Raw measurements can be easily input into \proglang{R}, combined with relevant meta-information and accordingly analysed.
The kinetics can be aggregated by estimating curve parameters using several methods.
Some of them have been specifically adapted for obtaining robust parameter estimates from Phenotype Microarray data.
Containers of \pkg{opm} data can easily be queried for and subset by using the integrated metadata and other information.
The raw kinetic data can be displayed with customized plotting functions.
In addition to 95\% confidence plots and enhanced heat-map graphics for visual comparisons of the estimated curve parameters, the package includes customized functionality for user-defined simultaneous multiple comparisons of group means.
It is also possible to discretize the curve parameters and to export them for reconstructing character evolution or inferring phylogenies with external programs.
Tabular and textual summaries suitable for, e.g., taxonomic journals can also be automatically created and customized.
Export and import in the \proglang{YAML} (or \proglang{JSON}) markup language facilitates the data exchange among labs.
All functionality is exemplified using real-world data sets that are part of the \pkg{opm} \proglang{R} package or are included in the accompanying data package \pkg{opmdata}.
}

\Keywords{Bootstrap, Cell Lines, \pkg{grofit}, Growth Curves, \pkg{lattice}, Metadata, Microbiology, Respiration Kinetics, Splines, \proglang{YAML}, \proglang{JSON}}

\Plainkeywords{bootstrap, cell lines, grofit, growth curves, lattice, metadata, microbiology, respiration kinetics, splines, YAML, JSON}

\Address{
  Markus G\"{o}ker\\
  Leibniz Institute DSMZ -- German Collection of Microorganisms and Cell Cultures\\
  Braunschweig\\
  \\
  Telephone: +49/531-2616-272\\
  Fax: +49/531-2616-237\\
  E-mail: \email{markus.goeker@dsmz.de}\\
  URL: \url{www.dsmz.de}\\
}


%% this must be included if Sweave is used (with % symbols):
%% need no \usepackage{Sweave.sty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

% NOTE: Rstudio might insert a line '\SweaveOpts{concordance=TRUE}' after '\begin{document}', which is removed again by the build script, as it causes warning messages during R CMD check.
% So please don't try to rescue that line, and don't rely on it being there.


%% so far adding a TOC proved unsuccessful -- apparently the JSS style doesn't allow for a TOC
%\tableofcontents
%\newpage


\section[Introduction]{Introduction}\label{introduction}

\subsection[Preamble for ``eager to start'' readers]{Preamble for ``eager to start'' readers}\label{preamble}

% Please avoid repetition as far as possible.
% No details here, only links.
% Remember: repetition causes a huge maintenance problem.

Readers who want to jump right into examples for applying \pkg{opm} to their data will find an overview of what the package can do for them in Figure~\ref{fig:work_flow}.
Next, Figure~\ref{fig:overview} should be looked at, as it lists the names of the functions that can be used in each step of the possible \pkg{opm} work flows.
Examples for each step would then be found in the according subsections of Section~\ref{application}.
An overview of these sections is provided in Section~\ref{methods overview}.

The single most important problem users reported to us when applying \pkg{opm} was that the input files could not be read.
This was uniformly due to the use of multi-plate CSV files.
But the most recent versions of the OmniLog\textregistered \ software can batch-export one plate per CSV file, and \pkg{opm} can split multi-plate CSV into files that can be input by the package.
See Section~\ref{methods import} for details and Section \ref{application import} for a usage example.

Details on the scientific background could well be skipped during a first reading.
The interested user would nevertheless find them in Section~\ref{scientific introduction}, including references for important functionality.

All web resources regarding \pkg{opm} are linked on its main website \url{http://opm.dsmz.de/}.


\subsection[Scientific introduction]{Scientific introduction}\label{scientific introduction}

The phenotype is regarded as the set of all types of traits of an organism \citep{mahner}.
The phenotype is of high biological relevance, as it is the phenotype which is the object of selection and, hence, is the level at which evolutionary directions are governed by adaptation processes \citep{mayr}.
It is also the phenotype which is of direct relevance to humans, for example in exploiting microorganisms for industrial purposes or in the combat of pathogenic organisms \citep{broadbent, mithani}.
In the study of single-cell living beings, such as bacteria, fungi, plant or animal cells, it is an important field of research to study the phenotype by measuring physiological activities as a response to environmental challenges.
These can be single carbon sources, which may be utilized as nutrients and hence trigger cellular respiration, or substances such as antibiotics, which may slow down or even inhibit cellular respiration, indicating a successful inhibitory effect on potentially pathogenic organisms.
The intensity of cellular respiration correlates with the production of NADH engendering a redox potential and thus a flow of electrons in the electron transport chain.
To measure cellular respiration in an experimental assay, this flow of electrons can be utilized to reduce a tetrazolium dye such as tetrazolium violet, thereby producing purple colour \citep{bochnersava}.
In principle, the more intense the colour, the larger the physiological activity.


% The following figure is first referred to in the section 'Introduction'.
% Make sure it remains mentioned there.
\begin{figure}
\scalebox{1.225}{
\includegraphics{opm_fig_1}
}
\caption{\label{fig:data}
Overview of the data assembly from an PM experiment and the possible additions using \pkg{opm}.
The raw colour-formation values result in sets of 96 raw kinetics per plate.
Using \pkg{opm}, they can be augmented by the information coded in the shape characteristics.
This yields 96 sets of parameters per plate, each containing four robustly estimated parameters that describe distinct aspects of the respective curve shape.
The \pkg{opm} package also offers tools for further combining this bundle of raw, aggregated and also discretized data of each single kinetic with meta-information on the organisms and/or experiments.
Based on this meta-information, a variety of visual and statistical comparison tools for either the raw or the aggregated data are available in \pkg{opm}.
}
\end{figure}


The Phenotype MicroArray (PM) system is capable of measuring a large number of phenotypes in a high-throughput system that uses such as tetrazolium detection approach.
About 2,000 distinct physiological challenges, such as the metabolism of single carbon sources for energy gain, the metabolism under varying osmolyte concentrations, and the response to varying growth-inhibitory substances are included in the PM microtiter plates \citep{bochner2001, bochner2009}.
The OmniLog\textregistered \ PM system records the colour formation in an automated setting (every 15 minutes) throughout the duration of the experiment, which may last up to several days.
Thus the experimenter ends up with high-dimensional sets of longitudinal data, the PM respiration kinetics.
For a detailed introduction into the experimental setup for obtaining OmniLog\textregistered \ PM respiration kinetic data we refer to the OmniLog\textregistered \ website (\url{http://www.biolog.com/}) and the associated hardware and software manuals.
Briefly, 96-well microtiter plates with substrates, dye, and bacterial cells are loaded into the OmniLog\textregistered \ reader, a hardware device which provides the appropriate incubation conditions and also automatically reads the intensity of colour formation during tetrazolium reduction.
The OmniLog\textregistered \ reader is driven by the \textit{Data Collection} software.
The stored results files, which are in a proprietary format, are then imported into the \textit{Data Management}, \textit{File Management/Kinetic Analysis}, and \textit{Parametric Analysis} software packages for data analysis.

In the case of positive reactions, the kinetics are expected to appear as (more or less regularly) sigmoidal curves in analogy to typical bacterial growth curves (Figure~\ref{fig:parameters}).
The intrinsic higher level of data complexity contains additional valuable biological information which can be extracted by exploring the shape characteristics of the recorded curves \citep{bisbin}.
These curve features can, in principle, unravel fundamental differences or similarities in the respiration behaviour of distinct organisms, which cannot be identified by the traditional end-point measurements alone.
But the meta-information of interest on the organisms and experimental conditions must also be available for a biologically meaningful data analysis and an according statistical assessment.

The motivation for the here presented \pkg{opm} package originated from (i) the need to overcome the limited graphical and analysis functions of the proprietary OmniLog\textregistered \ PM software and (ii) the desirability of an analysis system for this kind of data in a free statistical software environment such as \proglang{R} \citep{r}.
At the moment, the visualisation of the kinetics by the proprietary OmniLog\textregistered \ PM software is of limited quality, especially when simultaneously comparing the curves from more than two experiments.
Its calculation of curve parameters is rather crude \citep{vaas, biologInc}.
The statistical treatment of raw kinetic data and curve parameters would involve cumbersome manual and hence error-prone manipulations of data in typical spreadsheet applications before they may be imported into appropriate statistical software.
Finally, the amount of organismic or experimental metadata that can be added to the raw data is extremely limited.

Based on a previous study \citep{vaas} the here presented \pkg{opm} package offers functionalities for a fast, robust and comprehensive evaluation of PM respiration kinetics suitable for a wide range of experimental questions.

Using customized input functions, raw kinetic data can be transferred into \proglang{R}, stored as \proglang{S4} objects \citep{chambers} containing single or multiple OmniLog\textregistered \ PM plates and further processed.
The package features the statistically robust calculation and attachment of aggregated curve parameters including their (bootstrapped) confidence intervals.
Moreover, infrastructure is provided to merge this with any kind of additional metadata.
These complex data bundles can then be exported in \proglang{YAML} format (\url{http://www.yaml.org/}), which is a human-readable data serialization format that can be read by most common programming languages and facilitates fast and easy data exchange between laboratories.
Its subset, \proglang{JSON} (\url{http://www.json.org/}), can also be used, for instance if a proper \proglang{YAML} parser is unavailable.
As \pkg{opm} is also able to generate \proglang{R} matrices and data frames, output in CSV (character-separated values) files would also be easy.

Data evaluation includes the graphical display of the data such as the raw respiration curve kinetics or the confidence intervals of aggregated curve parameters.
With sophisticated selection methods the user is able to sort, group and arrange the data according the specific experimental questions in the plotting and analysis framework.
Since most addressed experimental questions require to statistically compare not only single curves, but distinct groups of curves, the package provides adapted functionality for performing simultaneous multiple comparisons of group means \citep{bretz}.
Because the definition of groups using stored metadata is highly flexible, the user is enabled to individually define contrast tests \citep{hsu}.

For further specific graphical or statistical analysis according to the needs of the users, the \pkg{opm} package organises and maintains the data such that any additional data exploration using other packages in the \proglang{R} environment are easily applicable.

The work flows described below include the input of raw kinetic data and integration of corresponding metadata, conversion into suitable storage formats, the computation of a set of four parameters sufficient for comprehensively describing the curves' shape (aggregated data), manipulating and querying the constructed objects, visualizing both raw kinetics and aggregated data, statistical comparison of group means, discretization of the curve parameters and corresponding export methods, obtaining additional information the substrates and setting global options.



\section[Methods]{Methods}\label{methods}


\subsection[Overview]{Overview}\label{methods overview}

In the following the possible work flows (see Figure~\ref{fig:work_flow}) for generating an \proglang{R} object that contains the kinetic raw data from one to several OmniLog\textregistered \ plates along with the corresponding metadata of interest, and optionally the aggregated and potentially also discretized curve parameters, are described.
It is explained how to analyse either raw data, metadata, aggregated data (curve parameters), or combinations of all of them, as stored in the respective \proglang{R} objects, by graphical and/or statistical approaches.


% The following figure is first referred to in the section 'Overview'.
% Make sure it remains mentioned there.
\begin{figure}
\scalebox{1.225}{
\includegraphics{opm_fig_2}
}
\caption{\label{fig:work_flow}
A depiction of the work flows possible within \pkg{opm} and its potential interplay with base \proglang{R}, add-on packages for \proglang{R} and third-party software.
See Figure~\ref{fig:overview} for the functions that can be used in the respective steps.
The package allows the user full flexibility with respect to the type of information added to the created \proglang{R} objects and to the order of steps in which this is achieved.
For example, it is possible to add first the metadata and to perform some of the later described analysis and second to aggregate the raw kinetics and go on with analysis of the aggregated values.
Discretization might frequently not be of interest because it causes loss of information.
Since experimental frameworks can be imagined where only very limited meta-information is available, it is also feasible to work without metadata at all.
}
\end{figure}


% Please keep the following paragraphs a brief as possible.
% Include cross-references but no details.
% Avoid repetition (of the previous and forthcoming chapters) as far as possible.
% Remember: repetition causes a huge maintenance problem.

The raw kinetic data can be exported by the proprietary OmniLog\textregistered \ software \textit{File Management/Kinetic Analysis} as CSV files and imported into the \pkg{opm} package using \code{read\_opm()}. 
This is explained in detail in section Section~\ref{methods import}, whereas corresponding code examples are found in Section~\ref{application import}.

Batch processing many files is also possible, even without starting an interactive \proglang{R} session.
This includes storage of the \pkg{opm} data in the \proglang{YAML} (or \proglang{JSON}) format, as detailed in Section~\ref{methods batch}.
Example code is given in  Section~\ref{application batch}.

All kinds of PM data can be enriched with metadata (see Figure~\ref{fig:data}).
The underlying principles are described in Section~\ref{methods metadata}, whereas example code for metadata management is included in Section~\ref{application metadata}.

To statistically analyse the biological information coded in the shape characteristics of the kinetics, four descriptive curve parameters are estimated, which is explained in detail in Section~\ref{methods aggregating}, whereas example code for curve-parameter estimation is provided in Section~\ref{application aggregating}.

The user may be interested to query or subset the objects generated by \pkg{opm}.
The underlying principles are described in Section~\ref{methods manipulation}, whereas example code for object management can be obtained from Section~\ref{application manipulation}.

The raw kinetic data can be plotted either as level plots or as XY plots, as explained in Section~\ref{methods plotting}.
The estimated curve parameters can be plotted either as confidence-interval plots, radial plots  or heat maps, which is described in Section~\ref{methods plotting-aggregated}.
See Section~\ref{application plotting} and Section~\ref{application plotting-aggregated}, respectively, for plotting example code.

To statistically compare curve parameters, tools for the multiple comparison of groups means have been adapted to PM data.
This allows for testing statistical hypothesis involving groups of plates or wells.
The principles are described in Section~\ref{methods group-means}, and example code is included in Section~\ref{application group-means}.

The aggregated data can be discretized and exported for phylogenetic analysis or reconstruction of character evolution with external phylogeny software.
The principle is outlined in Section~\ref{methods discrete-multistate}, whereas application examples are provided in Section~\ref{application discrete-phylogeny}.

The methods implemented in \pkg{opm} for classifying reactions as either ``positive'', ``negative'' or ``weak'' (ambiguous) are described in Section~\ref{methods discrete-binary}.
Example code, including the export of discretization results as  publication-ready tables, is included in Section~\ref{application discrete-table}.
Textual reports with or without formatting markup can also be produced, as exemplified in Section~\ref{application discrete-text}.
The discretization settings can be modified in detail; see Section~\ref{application discrete-finetuning}.

Furthermore, substrate informations can be accessed, including CAS numbers, KEGG and Metacyc IDs as far as they are available. Code examples are included in Section~\ref{application substrates}.

Finally, it is possible to modify settings that have an effect on multiple functions and/or on frequently used arguments. 
See Section~\ref{methods settings} for details and Section~\ref{application discrete-table} for a code example.

After a successful installation of \pkg{opm}, the complete \proglang{R} code extracted from this vignette (as well as all other vignette files) can be found \textit{via} \code{opm\_files("doc")}.


\subsection[Data import]{Data import}\label{methods import}

The proprietary OmniLog\textregistered \ PM data analysis software \textit{File Management/Kinetic Analysis} \citep{biologInc} can export the kinetic raw data from single or multiple plates as CSV files.
These contain a small amount of associated run information that has been entered at the interface of the OmniLog\textregistered \ PM \textit{Data Collection} software, which controls the OmniLog\textregistered \ reader.
Currently this generation of CSV files involves the creation of intermediary files with the extension ``d5e'' from the original ones with the extension ``oka''.
For use with \pkg{opm}, the raw kinetic data should be exported into a single CSV file for each measured plate.
The \pkg{opm} package currently does not support the input of several plates from PM-mode runs stored in a single CSV file, but it offers the function \code{split\_files()} for splitting old-style CSV files containing multiple plates.
(We refer to the CSV exports from the currently distributed OmniLog\textregistered \ PM \textit{File Management/Kinetic Analysis} software as ``old style''.
Forthcoming versions are expected to export the data in a slightly different CSV format we call ``new style''.
Please contact your local representative of the vendor for the latest software version.)

As of version 0.4-0, \pkg{opm} also supports the input of MicroStation\textregistered \ CSV files (frequently used in conjunction with EcoPlate\textregistered \ assay for microbial community analysis).
These files contain only end-point measurements but potentially several plates, which can nevertheless be input together with their potentially also rich meta-information.

The easiest way to load the raw kinetic data (as CSV files or as \proglang{YAML} or \proglang{JSON}) into \proglang{R} in a single step is using the function \code{read\_opm()} (see Figure~\ref{fig:work_flow}).
If raw data from only one single-plate OmniLog\textregistered \ PM are imported, the resulting object belongs to the \proglang{S4} class \proglang{OPM}.
This class for holding single-plate OmniLog\textregistered \ PM data originally only includes the (limited) meta-information read from the original input CSV files, but an arbitrary amount of metadata can be added later on (see Figure~\ref{fig:work_flow}).
If multiple plates are imported, the resulting object automatically belongs to the \proglang{S4} class \proglang{OPMS}.
In the \proglang{OPMS} class, data may have been obtained from distinct organisms and/or replicates, but must correspond to the same plate type and must contain the same wells (see Figure~\ref{fig:work_flow}).
The function \code{read\_opm()} has an argument ``convert'' which controls how sets of plates with distinct types are treated; for instance, the function can return a list of  \proglang{OPMS} objects, one for each encountered plate type.

The entire \proglang{S4} class hierarchy used by \pkg{opm} is shown in Figure~\ref{fig:class_hierarchy}.
A number of \proglang{S3} helper classes are also used by several functions.
Users come in direct contact only with the \proglang{OPM}, \proglang{OPMA}, \proglang{OPMD} and \proglang{OPMS} classes (see Figure~\ref{fig:overview}).
Once such objects are created they could also be stored in files using \code{save()} and read again using \code{load()} but \textit{not} using \code{dump()} and \code{source()} instead, respectively.
We would nevertheless recommend storage in \proglang{YAML} format.


\subsection[Batch conversion of many files]{Batch conversion of many files}\label{methods batch}

To process and store huge numbers of raw data files, the function \code{batch\_opm()} reads all OmniLog\textregistered \ CSV files (or \proglang{YAML} files previously generated with \pkg{opm}) within a given list of files and/or directories and converts them to \pkg{opm} \proglang{YAML} (or \proglang{JSON}) format.
It is possible to let \pkg{opm} automatically include metadata (Section~\ref{methods metadata}) and aggregated values (curve parameters) (Section~\ref{methods aggregating}) as well as discretized values (Section~\ref{methods discrete-binary}) during this conversion.
Alternatively, graphics files containing the output of \code{xy\_plot()} or \code{level\_plot()} can be batch-produced; see Section~\ref{methods plotting} for Details.
File selection and unselection using regular expressions or globbing patterns is integrated in the function.
The result from each file conversion is reported in detail, and a \textit{demo} mode is available for viewing the attempted file selections and conversions before actually running the (potentially time consuming) conversion process.
The package is accompanied by a command-line script ``run\_opm.R'', enabling the users to run the batch conversion without starting an interactive \proglang{R} session.
This script is guaranteed to run at least under \proglang{UNIX}-like operating systems.
On such systems it can also be run in parallel, making use of multi-core machines.


\subsection[Integration of metadata]{Integration of metadata}\label{methods metadata}

The interface of the \textit{Data Collection} software of the OmniLog\textregistered \ reader is restricted in size and contains only comparatively few fields for entering accompanying information  to each plate such as on the organism under study or the culture conditions.
Further, not all of these fields are exported together with the raw measurements.
The few metadata that come along with the imported CSV file can be accessed via \code{csv_data()}.
But for most experimental designs it is clearly necessary to add much more meta-information to the kinetic data.
It has to be emphasized that metadata can include all kind of describing characteristics of the observed organism(s) such as taxonomic affiliation, geographical and/or ecological origin, and of the performed experimental setting such as culture conditions, genetic modifications, physiological information of any kind and so on.

To this end, the \pkg{opm} user can integrate the metadata into \proglang{OPM} and \proglang{OPMS} objects using the function \code{include\_metadata()} (among other functions for this task; see Figure~\ref{fig:overview}).
Usually, the metadata are kept in a data frame which can conveniently be saved to, and generated directly from, a CSV file.
For an unambiguous match between the raw kinetic data in the \proglang{OPMS} object and the collected metadata, a unique identifier is needed.
This is, by default, provided by the combination of \textit{Setup Time} and \textit{Position}, which should unequivocally identify certain plates.
\textit{Setup Time} indicates the date and time at the precision of seconds of starting the batch read in the OmniLog\textregistered \ reader.
\textit{Position} indicates the position of the plate in the OmniLog\textregistered \ reader.
(For instance, \textit{10-A} indicates the plate sliding carriage number 10 in slot A of the reader, but for \pkg{opm} the meaning is irrelevant, as these entries only serves as identifiers.)
Both \textit{Setup Time} and \textit{Position} are automatically recorded by the OmniLog\textregistered \ reader \textit{Data Collection} software and are exported by the OmniLog\textregistered \ PM \textit{File Management/Kinetic Analysis} software into CSV files together with the raw kinetic data.

To facilitate the user-friendly compilation of metadata, \code{collect\_template()} generates a data frame (and additionally, if requested, a CSV file) in which each line represents a single PM plate.
The function \code{collect\_template()} by default automatically includes the \textit{Setup Time} and \textit{Position} of each plate into the data frame or file providing a structured template for the addition of metadata.
The user can subsequently add further columns describing any metadata of interest on any PM plate of interest.
The resulting data frame can then be queried for the information specific to each plate, and the corresponding row integrated into \proglang{OPM} or \proglang{OPMS} objects using \code{include\_metadata()}.
Whereas this function will usually result in non-nested metadata entries, \pkg{opm} allows one, in principle, to deal with arbitrarily nested meta-information.
Other functions for generating and modifying plate meta-information are listed in Figure~\ref{fig:overview}.
Thereby, the amount of meta-information added (and plates analysed) is only limited by the available computer memory.


% The following figure is already referred to in the section 'Data import'.
% Make sure it remains mentioned there.
\begin{figure}
\scalebox{1.225}{
\includegraphics{opm_fig_3}
}
\caption{\label{fig:class_hierarchy}
This picture shows the \proglang{S4} class hierarchy used by \pkg{opm}.
Class names are shown in bold within the boxes.
Boxes with dark background indicate virtual classes, those with light background indicate real classes whose objects can be created and manipulated by some code.
Arrows indicate either inheritance relationships (pointing from the parent to its child class) or object composition (pointing from the container class to its element class).
Note particularly that \proglang{OPM}, which only contains raw data, csv data and metadata, is the parent class of \proglang{OPMA}, which also contains aggregated data (and has methods for dealing with them).
\proglang{OPMD} inherits from \proglang{OPMA} and stores discretized curve parameters in addition to aggregated values.
\proglang{OPMS} is a container class that holds \proglang{OPM}, \proglang{OPMA} and/or \proglang{OPMD} objects.
These can usually co-occur in a single \proglang{OPMS} object but for some calculations the additional information in \proglang{OPMA} or \proglang{OPMD} objects is strictly required.
The query functions \code{has\_aggr()} and \code{has\_disc()} are available for checking from which kinds of objects an \proglang{OPMS} is composed.
See their help pages (e.g., \code{?has\_aggr}) and Section~\ref{application} for further details.
The non-virtual classes in the upper part of the figure are either well-known in \proglang{R} (e.g., matrices) or not directly manipulated by the user (\proglang{CMAT}).
}
\end{figure}


The user can provide additional information to the metadata data frame on the fly by calling the function \code{edit()}, which opens the \proglang{R} editor enabling the user to modify and add data.
Beside changing the metadata entries by using the \proglang{R} editor, the function \code{map\_metadata()} offers a secure way to map metadata within \proglang{OPMS} objects.
The replacement function \code{metadata()<-} enables the user to set the entire meta-information, or specific entries, directly.
If a data frame is used on the right side of the assignment whose number of rows is identical to the number of plates within the  \proglang{OPMS} object on the left side, each data-frame row is specifically added to the corresponding plate.

There are no restrictions regarding the stored metadata \textit{values} except for the fact that it usually makes not much sense to store factors.
It is safer to store character vectors instead because otherwise conversions might easily result in integer vectors instead of factors.
Where appropriate, factors would be created on-the-fly from character vectors by those methods that have to integrate metadata in data frames.
A \code{map\_metadata()} method is available that conducts an according cleaning of metadata entries.
With respect to the stored metadata \textit{names}, there are only very few restrictions, which are explained in Section~\ref{methods settings}.
In contrast to data frames it is not advisable to access metadata entries by position instead of by name.


\subsection[Aggregating data by estimating curve parameters]{Aggregating data by estimating curve parameters}\label{methods aggregating}

Descriptive curve parameters from the kinetic raw data can be calculated and included in \proglang{OPM} and \proglang{OPMS} objects using the function \code{do\_aggr()}.
Curve parameters can be extracted using a spline-based fitting procedure implemented in \pkg{opm}.
(Extraction of curve parameters through the fit of sigmoid functions proved for several PM curve shapes to yield biologically unrealistic values \citep{vaas} and have therefore not been implemented.)
Three different modelling alternatives for the splines exist:
(low-rank) cubic smoothing splines \citep{Reinsch:1967} as implemented in \code{smooth.spline} from the  \pkg{base} package, thin plate splines \citep[a generalization of smoothing splines]{Wood2003} and P-splines \citep{eilers}.
The latter two are implemented in the package \pkg{mgcv}.
Their settings have been specifically adapted for the application to PM data.
It is also possible to access methods from the package \pkg{grofit} \citep{kahm} or to use a native  implementation which is faster but only estimates two of the four parameters.
For historical reasons, ``grofit'' is the default but it is recommended to use the optimized ``splines'' methods.

The descriptive curve parameters  $\lambda$, $\mu$, A and AUC estimated by \pkg{opm} are shown in Figure~\ref{fig:parameters}.
In addition to the point estimates for the parameters from both model and spline, confidence limits can be calculated (for the spline-based approach \textit{via} bootstrapping), with 95\% being the default value \citep{efron}.
But confidence intervals and according group means can also be calculated from experimental repetitions, as explained in Section~\ref{methods plotting-aggregated}.
Attaching the aggregated data to an \proglang{OPM} object yields an object of the class \proglang{OPMA}, which can also be stored within an \proglang{OPMS} container object.


\begin{figure}
\scalebox{1.225}{
\includegraphics{opm_fig_4}
}
\caption{\label{fig:parameters}
A schematic depiction of a typical respiration (or growth) curve and the parameters estimated by \pkg{opm}.
The descriptive curve parameters are the lag phase $\lambda$, the respiration (or growth) rate $\mu$ (corresponding to the steepness of the slope), the maximum cell respiration (or growth) A (corresponding to the maximum value of the curve) and the area under the curve AUC.
Note that many respiration curves, even if representing a clearly positive reaction, do not correspond to this idealized scheme.
The parameters can nevertheless be robustly estimated from deviating curves, particularly \textit{via} spline fits \citep{vaas}.
}
\end{figure}


\subsection[Manipulation of OPM and OPMS data]{Manipulation of \proglang{OPM} and \proglang{OPMS} data}\label{methods manipulation}

As usual, data analysis starts with data exploration for which the user may wish to query and subset \proglang{OPM} and \proglang{OPMS} objects (Figure~\ref{fig:overview}).
It is easy to select specific wells and time points from \proglang{OPM} or \proglang{OPMS} objects.
It also straightforward to select specific \proglang{OPM} objects from an \proglang{OPMS} object that contains them.
To this end, \proglang{OPM} and \proglang{OPMS} methods for the generic function \code{subset()} and \proglang{R}'s bracket operator have been implemented. 
Particularly powerful are the options for metadata-based subsetting. 
The composition of \proglang{OPM} and \proglang{OPMS} objects, and the implemented methods of the classes, permit queries for the presence of a specific metadata key or a specific value of a specific metadata key, or a specific combination of values and/or keys, and also enable the user to subset \proglang{OPMS} objects accordingly.

But a plethora of methods for querying other aspects of \proglang{OPM} and \proglang{OPMS} objects have also been implemented.
Standard operations such as sorting objects and making them unique are also available for the \proglang{OPM} and \proglang{OPMS} classes.
Of course, \proglang{OPMS} objects can not only be subset but it it also possible to build up larger \proglang{OPMS} objects by combining \proglang{OPMS} and \proglang{OPM} objects using specialized methods for the \code{c()} generic function and the \code{+} operator as well as the very flexible function \code{opms()}.
Moreover, an \proglang{OPMS} method for \code{merge()} has been implemented, that allows for concatenating PM measurements that represent subsequent runs of the same plate.
This has successfully been applied to slow-growing organisms in the bacterial genus \textit{Geodermatophilus}, which had to be measured three times consecutively in the OmniLog\textregistered \ instrument (up to twelve days in total) \citep{montero, montero2013}.

It is also possible to convert the \proglang{OPM} or \proglang{OPMS} objects to other objects for an independent exploration by the user.
This can be done within \proglang{R}, based on a variety of distinct data-frame or matrix objects that can be generated.
But export in some useful file formats is also possible.


\begin{figure}
\scalebox{1.225}{
\includegraphics{opm_fig_5}
}
\caption{\label{fig:overview}
This scheme provides a detailed overview of the possible strategies and appropriate functions for data analysis using the \pkg{opm} package.
Beginning with one to several CSV files containing raw kinetic data exported by the proprietary OmniLog\textregistered \ software \textit{File Management/Kinetic Analysis}, or \proglang{YAML} or \proglang{JSON} files that have been generated in previous \pkg{opm} runs, a variety of work flows are possible for setting up  \proglang{OPM} or \proglang{OPMS} objects.
Additionally, methods for metadata management, plotting the data in a customized manner, querying and sub-setting the generated objects, statistical comparison of multiple group means, and data-conversion tools including discretization, report generation and output in files are provided.
}
\end{figure}


\subsection[Plotting functions for raw data]{Plotting functions for raw data}\label{methods plotting}

The function \code{xy\_plot()} displays the raw measurements on the y-axis in dependency on the time on the x-axis.
For each well one sub-panel is drawn, and the user is free to colourize the plotted curves by either their affiliation to a specific plate or by a combination of metadata entries of choice.
By default the panels are arranged according to the factual microtiter plate dimensions (eight rows labelled A to H $\times$ twelve columns labelled 01-12), but other user-defined arrangements are easily feasible because the plates can be subset by selecting specific wells.
Every panel is annotated with the microtiter plate numbering (A01 to H12) and additionally or alternatively with the substrate name (given the plate type, the \pkg{opm} package can translate all well coordinates to substrate names).
Thus, the function enables the user to compare the curve data in a customized and useful arrangement \citep{vaas}.

The function \code{level\_plot()} provides false-colour level plots from the raw respiration measurements over time.
Each respiration curve can be displayed as a thin horizontal line, in which the measured respiration value (in OmniLog\textregistered \ units) is represented by colour, while the x-axes indicates the measurement times.
With increasing respiration measurement values, the displayed colour changes (by default) from light yellow into dark orange and brownish.
The user can obtain an overview in a compacted design \citep{vaas}.
This plot offers a display format which is especially powerful in uncovering general differences between plates, for example longer lag phases or smaller AUC values across the majority of wells.
By default one sub-panel in the level plot corresponds to one complete plate comprising 96 lines, but as in the case of \code{xy\_plot()} plotting could also be preceded by creating subsets of the plates.


\subsection[Plotting the aggregated data]{Plotting the aggregated data}\label{methods plotting-aggregated}

For the graphical representation of the aggregated data, namely point estimators and corresponding confidence limits for the curve parameters of selected curves, the function \code{ci\_plot()} is available.
The characteristics of different curves assembled into a single overview facilitates the interpretation and comparison of user-defined data subsets arranged according to the technical and/or biological repetition structure or other aspects of the experimental design \citep{vaas}.

When analysing empirically obtained measurements such as PM data it is important to consider possible systematic variations and to control for those by normalization.
For a PM experiment the purpose of such a normalization is to minimize systematic variations in the aggregated curve parameters so as to more easily recognize biological differences, as well as to allow for the comparison of parameters across plates processed in different experimental runs.
The underlying ideas are mainly derived from DNA-microarray experiments for measuring gene-expression levels \citep{quackenbush}.

Using \code{extract()} the user can select certain aggregated or discretized values into common matrices or data frames.
If applied a second time to a previously generated data frame, \code{extract()} can compute point estimates and their respective confidence intervals for individually defined experimental groups.
Optionally, normalization by subtracting, or dividing through, the plate-wise means (across all 96 wells) or well-wise means (across all plates that contain this well) can be conducted beforehand.
Although this method is intended mainly as a helper function for \code{ci\_plot()}, it can be quite useful for specific normalization purposes, for example when data were derived before and after servicing the Omnilog\textregistered \ facility, which might result in shifting the measurements by a certain amount.
In conjunction with \code{extract()}, \code{ci\_plot()} allows for visualizing point estimates and confidence intervals of groups of parameter estimates.
For visualizing differences between groups and their confidence intervals, see \code{opm\_mcp()} as described in Section~\ref{methods group-means}.
 
Additionally, the package offers the possibility of plotting the aggregated curve parameters as a heat map \textit{via} the function \code{heat\_map()}.
Heat maps appear particularly powerful for visualizing the outcomes of PM experiment because dendrograms inferred from both the substrates and the plates can be used to rearrange the plot.
Since the user is free to define the metadata to be used for the annotation of the plot and the clustering analysis, this tool provides a powerful feature for data exploration in specialized contexts.
For instance, the naming scheme of the individual plates can be devised by selecting associated metadata.
It is also possible to automatically construct row groups by selecting the same or other meta-information.
\code{heat\_map()} is mainly a wrapper for the \code{heatmap()} functions from either the \pkg{stats} or the \pkg{gplots} \proglang{R} package, but contains some useful adaptations to PM data.
It facilitates the selection of a clustering algorithm and the construction of row and column groups, and provides more appropriate default solutions for row and column descriptions sizes.
(We suppose that in most situations the pictures produced by \code{heat\_map()} should not need to be manually adapted in these respects.)

Finally, \pkg{opm} enables the user to plot aggregated values as radial plots using an eponymous function, which is mainly a wrapper for the \code{radial.plot()} function from the \pkg{plotrix} package adapted to the typical \pkg{opm} objects.
\code{radial\_plot()} displays a plot of radial lines, polygons or symbols, or a combination of these, centred at the midpoint of the plot frame, the lengths, vertices or positions corresponding to the numeric magnitudes of the data values.


\subsection[Statistical comparisons of group means]{Statistical comparisons of group means}\label{methods group-means}

Besides comparing single curves, the user may also be interested in statistically comparing the mean values of distinct groups of curves.
For example, imagine the comparison of four different bacteria using GEN-III microplates.
Assume that for each bacterial strain, ten replicates have been performed.
(An according example dataset is actually available in the \pkg{opmdata} package.)
Do these four bacteria differ in, e.g., the mean value of, e.g., curve parameter A of, e.g, well A01?
Here, a statistical comparison of four groups (four organisms), each containing ten values (curve parameter A of 10 replicates of well A01), would need to be performed.
Statistically, this requires simultaneous inferences across multiple questions \citep{hothorn}.
To address this issue the function \code{opm_mcp()} performs simultaneous multiple comparisons of group means by internally calling \code{glht()} from the \pkg{multcomp} package \citep{hothorn} but providing an easier interface for it, specifically adapted to the typical objects used within \pkg{opm}.
By referring to available metadata and/or the substrate names, the user is able to define groups of interest, set up a model of choice and perform multiple comparison of group means on individually specified contrasts \citep{bretz, hsu}.
The choice of appropriate models and contrasts will be explained in detail below.
As comparisons of the different curve parameters are performed separately, it is possible to ask very specific questions on differences between curve shapes.

At this point, it is necessary to highlight the power and flexibility of simultaneous multiple comparison procedures and encourage the user to apply contrast tests on individually designed sets of mean comparisons rather than to employ the probably more popular classical ANOVA approaches, which perform F-tests.
In general, such F-tests \textit{only} provide global information about main effects and interaction effects.
That is, only the significance of a result yields evidence for a difference in the means among any of the considered treatments.
For example, in the framework of PM data, a significant F-test on the effect of the substrate would indicate that at least two of the substrates cause distinct respiration. 
Considering that each PM experiment encounters up to 96 different substrates per plate (overall up to 2,000), this information would obviously be nearly useless.
Moreover, F-tests neither provide information about effect sizes nor do they ease to address comparisons of particular interest \citep{schaarschmidt}.

We thus opine that the very most underlying questions in PM experiments are best expressed as a set of particular mean comparisons, resulting in a multiple-comparison problem \citep{hochberg}.
However, if an increasing number of hypotheses is tested, with the number of true hypotheses unknown, the probability of at least one wrong testing decision also increases.
That is, if an increasing number of groups is compared to each other, conclusions on significant differences between a pair of groups are increasingly likely to be wrong.
Thus the so-called family-wise error-rate, which is essentially the probability of at least one false rejection among all the null hypotheses, needs to be controlled \citep{tukey}.
The here internally employed functionality from the package \pkg{multcomp} provides solutions for all listed difficulties, since it allows for testing a user-defined set of contrasts based on a broad range of model types while internally controlling the family-wise error-rate.  

Users of multiple-comparison procedures, especially of simultaneous multiple contrast tests as applied here, are encouraged to have a look at the books by \citep{hochberg} and \citep{hsu}. 

Especially in situations where groups are defined by more than one metadata entry the evaluation of differences of treatment means may result in quite complex models. 
Then, the application of \textit{cell-means models} (also known as \textit{pseudo-one-way layouts}) as discussed in \citep{schaarschmidt}) is strongly encouraged.
In this approach estimators for treatment and variance are derived from a model with all treatments combined in a single factor. 
Technically, this necessitates to merge the defining metadata variables into a single.
An according example is given in Section~\ref{application metadata}, whereas the computation of multiple comparisons using a \textit{cell-means model} is shown in Section~\ref{application group-means}.

The function \code{opm\_mcp()} internally reshapes the data into a ``flat'' data frame containing one column for the chosen parameter value, one column for the well (substrate) name and optionally additional columns for the selected metadata.
For performing the testing procedure, a model has to be stated that specifies the factor levels that determine the grouping \citep{searle, hothorn}.
The \code{opm\_mcp()} function allows for applying such testing directly to \proglang{OPMS} objects, obtaining these factors from stored metadata.


\subsection[Discretizing and export for phylogenetic analysis]{Discretizing the aggregated data and export for phylogenetic analysis}\label{methods discrete-multistate}

Whereas the main data-analysis strategies of the \pkg{opm} package are based on quantitative, continuous data (as described in the previous chapters), users may nevertheless be interested in discretizing the estimated curve parameters.
Discretization transfers continuous data into discrete ones.
For example, continuous values ranging from 0 to 400 could be discretized into the three states ``low'' (from 0 to 100), ``intermediate'' (from 101 to 200), and ``high'' (from 201 to 400).
Discretizing the data is necessary for analysing them with external programs that cannot deal with continuous characters.
Indeed, phylogeny software such as \proglang{PAUP*} \citep{swoff} and \proglang{RAxML} \citep{stamatakis} is limited to at most 32 distinct character states.
(To the best of our knowledge, a maximum-parsimony algorithm applicable directly to continuous data has only been implemented in \proglang{TNT} \citep{goloboff}.)
Phylogenetic studies of PM data, or at least reconstructions of PM character evolution, are of interest because such phenotypic information is frequently used for taxonomic purposes in microorganisms, and here phylogenetic inference methods might be superior to clustering algorithms \citep{felsenstein}.
But tabular or textual descriptions of physiological reactions classified into negative, weak (ambiguous) and positive reactions (see Section~\ref{methods discrete-binary} for details) are of even greater relevance in current microbial taxonomy \citep{tindall}.

The \pkg{opm} package includes data-transformation functionality within the \code{discrete()} methods for coding continuous characters by assigning them to a given number of equal-width categories within a given range.
For example, for the parameter A (the maximum curve height) the theoretically possible range between 0 and 400 OmniLog\textregistered \ units could be used.
The data should then be analysed under ordered (Wagner) maximum parsimony in \proglang{PAUP*} \citep{farris} or with the options for ordered multi-state phenotypic characters in \proglang{RAxML} \citep{berger}, or corresponding settings in other programs, to minimize the loss of information caused by discretizing the values.
For this reason, this kind of unsupervised, equal-width-intervals discretization \citep{dougherty,ventura}, even though simple, appears appropriate for this task.
In this context, it also makes not much sense to let a discretization method determine the number of categories because they are not dictated by some property of the data but by the limitations of the subsequently to apply analysis software.
The \pkg{opm} package offers appropriate functions for data export.

\subsection[Determining positive and negative reactions and displaying them as text or table]{Determining positive and negative reactions and displaying them as text or table}\label{methods discrete-binary}

If users wanted to discretize the parameters into ``positive'' and ``negative'' results, this would apparently make most sense for the parameter A because here it is not of interest when and how fast a reaction starts (which would be coded in $\lambda$ and $\mu$, respectively) or how much overall respiration was achieved (as coded in AUC) but whether or not a reaction takes place at all.
Unfortunately, PM data frequently result in a continuum of A values between clearly negative and clearly positive reactions.
For instance, the distribution of A in the example datasets distributed with the \pkg{opm} and \pkg{opmdata} packages is obviously bimodal, but contains a large number of intermediary values.
For this reason, the \code{discrete()} methods and their more user-friendly wrapper \code{do\_disc()} offer a gap-mode discretization by interpreting a given range of values (within the overall range of observations) as ``ambiguous''.
Values below would then be coded as negative, values above the range as positive, and values within the range as either missing information or an intermediary state, ``weak''.
This range could be determined by some discretization approach known from the literature \citep{dougherty,ventura}.

The \pkg{opm} package offers its automated determination using k-means partitioning as implemented in \pkg{Ckmeans.1d.dp} \citep{song2011}, using an exact algorithm for one-dimensional data.
Alternatively, an algorithm implemented in \code{best\_cutoff()} is available, but it requires measurement replicates (which are highly recommended, if not mandatory, anyway) accordingly annotated in the metadata.
Both methods are accessible \textit{via} \code{do\_disc()}.
Export as richly annotated, publication-ready \proglang{HTML} table or text is possible using \code{phylo\_data()} and \code{listing()}.
If analysis with phylogenetic programs was of interest, in the case of an intermediary state the data should then be analysed as described above.
If intermediary values were coded as missing information they could be analysed under either Wagner or unordered (Fitch) maximum parsimony in \proglang{PAUP*} \citep{farris, fitch} or with the options for binary phenotypic characters in \proglang{RAxML} \citep{berger}, or corresponding settings in other programs.


\subsection[Global settings]{Global settings}\label{methods settings}

It is possible to modify settings that have an effect on multiple functions and/or on frequently used arguments globally using \code{opm\_opt()}.
This allows the user to adopt \pkg{opm} to personal preferences and to thereby substantially decrease coding effort.
It is checked that the novel values inherit from the same class(es) than the old ones.
Usage examples are provided in several sections (e.g., Section~\ref{application discrete-table}).
The function \code{param_names()} yields the spelling of the curve parameters used by \pkg{opm}.
It also displays the set of names that are used by some methods that have to compile metadata entries with other columns.
It is thus not impossible, but discouraged, to use these names as metadata keys.
The same holds for (non-syntactical) names starting with an underscore and followed by capital letters, as such names are temporarily used by some methods in intermediary objects together with the metadata.



\section[Program application]{Program application}\label{application}


\subsection[Overview]{Overview}\label{application overview}

% Set some stuff up that makes the output nicer and guarantees that everything runs.
% Think carefully before modifying anything here.
%
<<label=chunk.setup, echo=FALSE>>=
options(prompt = "R> ")
options(continue = "   ")
options(useFancyQuotes = FALSE)
library("methods")
@

Before starting, the \pkg{opm} package should be loaded into an \proglang{R} session as follows:

<<label=load.library>>=
library(opm)
@

The example dataset distributed with the package \citep{vaas} comprises the results from running 114 GEN-III plates (BIOLOG Inc.) in the PM mode of the OmniLog\textregistered \ reader.
The organisms used were two strains of \textit{Escherichia coli} (DSM 18039 $=$ K1 and the type strain DSM 30083\textsuperscript{T}) and two strains of \textit{Pseudomonas aeruginosa} (DSM 1707 and 429SC \citep{Selezska2012}).
The strains with a DSM number could be ordered from the Leibniz Institute DSMZ -- German Collection of Microorganisms and Cell Cultures (\url{http://www.dsmz.de/}).

Each strain was measured in two biological replicates, each comprising ten technical replicates, yielding a total of 80 plates.
To additionally investigate the impact of the growth age of cultures on the technical and biological reproducibility of the PM respiration kinetics, strain \textit{E. coli} DSM 18039 was grown on solid LB medium for nine different durations, from 16.75 h (t1) to 40.33 h (t9), respectively.
For each growth duration four technical replicates were performed except for t9 (which was repeated only twice), yielding 34 plates for this time-series experiment.
All biological and experimental details of this dataset have been described previously \citep{vaas}.

Two subsets of the data, \code{vaas\_1} and \code{vaas\_4}, are included in \pkg{opm}.
Use \code{?vaas\_1} and \code{?vaas\_4} to view their help pages, and have a look at the objects as follows:

<<label=data.objects, results=hide>>=
vaas_1
vaas_4
@

The entire dataset, stored in the object \code{vaas\_et\_al}, comes with the supporting package \pkg{opmdata} and can (if that package is installed, of course) be loaded using:

<<label=big.data>>=
data(vaas_et_al, package = "opmdata")
@

To view its help page, use \code{?opmdata::vaas\_et\_al}.

The metadata included in these objects comprise seven entries.
The entry \textit{Experiment} denotes the biological replicate or the affiliation to the time-series experiments.
The keys \textit{Species} and \textit{Strain} refer to the organism used for the respective experiment (see above), and \textit{Slot} (either \textit{A} or \textit{B}) indicates whether the plate was placed in the left or the right half of the OmniLog\textregistered \ reader.
(Note that for an assessment of the reproducibility of the curves the slot is occasionally of relevance.)
Two additional entries contain the index of the time point and the corresponding sample point in minutes for the time series experiment.
The key \textit{Plate number} indicates the technical replicate (per biological replicate).
The combination of the keys \textit{Strains}, \textit{Species}, \textit{Experiment} and \textit{Plate number} results in a unique label which unequivocally annotates every single plate.


\subsection[Data import]{Data import}\label{application import}

The following code describes the import of the OmniLog\textregistered \ CSV file(s) into the \pkg{opm} package.
In the \pkg{opm} manual and all help pages, all functions relevant for data import are contained in a family of functions called ``IO-functions'' with according cross-references.

The CSV files with the OmniLog\textregistered \ raw data should be stored in one to several user-defined folders.
Setting the working directory of \proglang{R} to the parent folder of these using \code{setwd()} frequently facilitates file selection, but in principle the user can provide any number of paths to input files and/or directories containing such files to the function \code{read\_opm()}, which can load several CSV files (and also \proglang{YAML} or \proglang{JSON} files generated by \pkg{opm}) at once.
A restriction of the input functions is that they can solely read CSV files that only contain the measurements from a single plate per file (either a PM plate or a single GEN-III plate measured in either PM- or identification modus).
But the package contains a function \code{split_files()}, which can be used to split CSV files with multiple plates into one file per plate.

To illustrate the file import step by step, a set of input CSV example files is provided with the package.
Before starting, remember that the \pkg{opm} package must be loaded.
Then use the built-in function \code{opm\_files()} to find the example files in your \proglang{R} installation:
<<label=files, results=hide>>=
files <- opm_files("testdata")
files
@
Then check whether this returned a vector of nine file names, including the full path to their location in the file system.
(It might fail in very unusual \proglang{R} installation situations; in that case, the files must be found manually.)
For demonstration purposes, the test data contain data from EcoPlate\textregistered \, Gen-III, PM01 and PM20 plate types. 
One of these files contains multiple plates and acts as an example for \code{split_files()}; the other ones can be read directly.

As a demonstration of file splitting, consider the following code, which creates single-plate CSV files from the multi-plate file that comes with \pkg{opm}:

<<label=file.splitting, results=hide>>=
multi.plate.file <- grep("Multiple", files,
  value = TRUE, ignore.case = TRUE)
multi.plate.file
list.files()
split_files(multi.plate.file, '^("Data File",|Data File)', getwd())
list.files()
@

Three additional files should be visible in the working directory, consecutively numbered but using the base name of the input file.
These could now be read with \code{read\_opm()}, but we will use other files in the next paragraph and tidy up now:

<<label=tidy.up.I, results=hide>>=
rm(multi.plate.file)
unlink(grep("Multiple-0000", list.files(),
  value = TRUE, ignore.case = TRUE))
@

Using \code{read\_opm()}, from a given vector of file and/or directory names, files can be easily selected and deselected using globbing or regular-expression patterns.
For instance, for reading the three example files in ``new style'' CSV format (see Section~\ref{methods import}), use the following code.

<<label=example.opm, results=hide>>=
example.opm <- read_opm(files, include = "*Example_?.csv.xz")
summary(example.opm)
@

After performing this step, the \proglang{OPMS} object contains three plates, as indicated by the \code{summary()} function.

Instead of a single file name the user could also provide several file names to \code{read\_opm()}, or a mixture of file and directory names.
If these were contained as subdirectories of the current working directory, \code{read\_opm(".")} or \code{read\_opm(getwd())} would be sufficient to input these files.
To filter the files with patterns, the arguments \code{exclude} and \code{include} are available.
There is also a \textit{demo} mode allowing the user to check the effect of each argument before actually reading files.
One can use the \code{gen.iii} argument to trigger the automated conversion of the plate type to, e.g., GEN-III or ``ECO'' plates run in ``PM'' mode, or convert later on using the \code{gen\_iii()} function itself.
Plate-type conversions to one of the ``PM'' modes are disallowed (and are, to the best of our knowledge, not relevant in practice anyway).
The plate type is crucial, as it is disallowed to integrate distinct plate types into a single \proglang{OPMS} objects.
The reason is that comparing the same well positions from distinct plate types would be almost always equivalent to comparing apples and oranges.

If more than one plate of the same plate type is read, however, data from all files are automatically integrated into a single \proglang{OPMS} object.
To read plates from several types at once, the \code{convert} argument is useful.
If one uses \code{read\_opm(..., convert = "grp")}, a named list is created with, as each list element, one \proglang{OPM} or \proglang{OPMS} object per plate type, depending on whether only a single plate of that plate type, or several such plates, have been found.
For instance, for inputting all example files (except for the one with multiple plates), consider the following code:

<<label=many.plates, results=hide>>=
many.plates <- read_opm(files, exclude = "*Multiple*", convert = "grp")
summary(many.plates)
summary(many.plates$PM01)
rm(many.plates) # tidy up
@

This yields the data from plates with distinct plate types in a single object.
Note that the objects for each encountered plate type can easily be accessed \textit{via} the names of the list.
More example code is available \textit{via} \code{opm\_files("examples")}.

A single plate could also be imported using \code{read\_single\_opm}.
But this might only occasionally be useful, as \code{read\_opm} can cope with single files, too.


\subsection[Batch conversion of many files]{Batch conversion of many files}\label{application batch}

In addition to \code{read\_opm()} and \code{read\_single\_opm()} (Section~\ref{application import}), which need to be called before an interactive exploration of PM data, batch-processing large numbers of files by converting them from CSV (or previously generated \proglang{YAML} or \proglang{JSON}) to \proglang{YAML} or \proglang{JSON} format, is also possible.
This optionally includes aggregating the raw data by estimating curve parameters (Section~\ref{application aggregating}), discretizing these parameters (Section~\ref{application discrete-text}) and integrating metadata (Section~\ref{application metadata}). 
Again there is a \textit{demo} mode to first investigate the attempted conversions:

<<label= batch.opm.I, results=hide, width=10>>=
batch_opm(files, include = "*Example_?.csv.xz",
  aggr.args = list(boot = 100, method = "opm-fast"),
  outdir = ".", demo = TRUE)
@

The arguments \code{aggr.args}, \code{disc.args} and \code{md.args} control aggregation, discretization and metadata incorporation, respectively.
Details on all three processes are given in the according sections, and for the exact use of these arguments see the \pkg{opm} manual, entering \code{?batch\_opm}.

The following command would read three of the seven example input files, estimate two of the four curve parameters using the fast native method including 100 rounds of bootstrapping, and store the resulting \proglang{YAML} files (one per plate) in the current working directory (given by ``.''):

<<label=batch.opm.II, results=hide, width=10>>=
batch.result <- batch_opm(files, include = "*Example_?.csv.xz",
  outdir = ".",
  aggr.args = list(boot = 100, method = "opm-fast"))
@

By default, progress messages are printed to the screen.
The return value, here assigned to the \code{batch.result} variable, also contains all information about the success of the individual file conversions.

The ``run\_opm.R'' script distributed with the package is an \proglang{Rscript}-dependent command-line tool for non-interactively running such file conversions.
Its location in the file system can be obtained using

<<label=scripts, results=hide, width=10>>=
opm_files("scripts")
@

Regarding its use, see the documentation of \proglang{Rscript} for details (enter \code{?Rscript} at the \proglang{R} prompt) and watch the help output of this script (try \code{system(opm_files("scripts"))}).


\subsection[Integration and manipulation of metadata]{Integration and manipulation of metadata}\label{application metadata}

Several ways for linking metadata to \proglang{OPM} or \proglang{OPMS} objects are possible.
The easiest one is probably the batch-inclusion after creating a template with plate identifiers associating it with metadata.
In the first step, either a data frame to be manipulated within \proglang{R} or a CSV file to be modified with a suitable editor are created.
The \pkg{opm} package supports metadata integration by creating a template for such a table from an \proglang{OPM} or \proglang{OPMS} objects that contains plate identifiers in the first columns; by default the keys \textit{Setup Time}, \textit{Position} and \textit{File}.
These data must not be changed, ensuring that the package can later on link the metadata to the dedicated plates according to these identifiers.

In the \pkg{opm} manual and help pages, most functions relevant for metadata manipulation are contained in a family called ``metadata-functions'' with according cross-references.
For the collection of a metadata template in a data frame to be manipulated in \proglang{R}, use this command:
<<label=collect.template.I, width=9>>=
metadata.example <- collect_template(files, include = "*Example_?.csv.xz")
@

For the generation of a metadata template file, the following command can be used:
<<label=collect.template.II, width=9>>=
collect_template(files, include = "*Example_?.csv.xz",
  outfile = "example_metadata.csv")
@
This will result in a file ``example\_metadata.csv'' in the current working directory (whose name is accessible using \code{getwd()}).
If other metadata have previously been collected, by default a pre-existing file with the same name will be reused.
The pre-defined columns will be respected, novel rows be added, old metadata will be kept and identifiers for novel files will be included and their so far empty metadata columns are set to missing data (NA).
You can also provide the location of another previously created metadata file with the \code{collect\_template()} argument \code{previous}.

The generated CSV file could then be edited using external software; for the purpose of this tutorial, we load it directly and manipulate it in \proglang{R}.
To avoid the usual changes in data format and header of the table during the import a customized import function was implemented as a wrapper for \code{read.delim()}:
<<label=to.metadata.I, width=8>>=
metadata.example <- to_metadata("example_metadata.csv")
@
Per default, this expects CSV columns separated by tabulators, with the fields protected by quotes.
To input other formats, consider the \code{sep} argument for defining an alternative column separator, as well as the \code{strip.white} argument for turning the removal of whitespace at the beginning and end of the fields on or off (which is relevant if a spreadsheet program exports CSV \textit{without} quotes).

Now the user could add information to the data frame by calling \code{edit()}, which would open the \proglang{R} editor, or by any other way of manipulating data frames in \proglang{R}.
New columns could be defined, or the existing metadata modified.
But the first columns must remain unchanged because they are needed to identify individual PM plates for linking them to their meta-information.
As an example, we here add an (arbitrary) \textit{Colour} column with the values ``blue'', ``red'' and ``yellow'' and another (arbitrary) \textit{Integer} column with the integer values 10, 20 and 30:

<<label=add.meta.column, width=8>>=
metadata.example$Colour <- c("blue", "red", "yellow")
metadata.example$Integer <- c(10L, 20L, 30L)
@

Now the metadata are ready to be included into the previously generated \proglang{OPMS} object:

<<label=include.metadata.I, width=8>>=
example.opm <- include_metadata(example.opm, md = metadata.example)
@

The metadata could then be received as follows:
<<label=metadata, results=hide>>=
metadata(example.opm)
@

This returns the entire metadata entries as a list.
By default only the added metadata are included in the object, but not the identifiers used for assigning data-frame rows to plates.

One might want to remove the file as it is not needed any more:
<<label=tidy.up.II, width=8>>=
unlink("example_metadata.csv")
@

A couple of other functions have been implemented for manipulating metadata included in \proglang{OPM} and \proglang{OPMS} objects.
For instance, the entire meta-information, or specific entries, can be set using the replacement function \code{metadata()<-}.
Setting a specific entry named \code{key} to a specific value \code{value} in all plates would be accomplished by \code{metadata(example.opm, key) <- value}.
If the right side of the assignment is a data frame with the same length as the \proglang{OPMS} object, each row would be specifically assigned to the \proglang{OPM} object with the same index.
This comes handy for adding the \code{csv\_data()} selected or all information from the OmniLog\textregistered \ CSV files to the metadata:

<<label=to.metadata.II, results=hide>>=
metadata(example.opm)
metadata(example.opm) <- to_metadata(csv_data(example.opm))[, 
  c("Strain Name", "Sample Number")]
metadata(example.opm)
@

You might note that ``Sample Number'' is a misnomer in these datasets.
(One of the fields in the interface of the \textit{Data Collection} software of the OmniLog\textregistered \ reader had been defined as ``Sample Number'', but the operator entered species and strain designations into this field.)
In this and similar cases, modifying metadata in-place is of interest, which can be accomplished using \code{map\_metadata()}.
This function would return a novel \proglang{OPMS} (or \proglang{OPM}) object.
Its formula method is particularly powerful.

<<label=map.metadata.I, results=hide>>=
metadata(example.opm)
metadata(map_metadata(example.opm, Organism ~ `Sample Number`))
@

This works by converting the left side of the formula into a metadata key and evaluating the right side of the formula in the context of the metadata entries that have already been added.
As result, a new metadata entry is created, with ``Organism'' as key and the entry from ``Sample Number'' as value.
``Sample Number'' must be quoted because it contains a special character (the blank).

But we have not yet removed the aptly named ``Sample Number'' entries.
Here, it is useful that all operators (except for \code{\$} and other high-precedence operators, which can be used for defining nested keys) on the left side, if present, would be changed by \code{map_metadata()} into a call to \code{list()}.
The resulting list would be flattened and treated as a list of metadata keys.
Hence it is possible to define several keys at once.
The right side, once evaluated, would be recycled accordingly.
Thus we can clean up our metadata in a single line of code:

<<label=clean.metadata, results=hide, width=8>>=
metadata(map_metadata(example.opm,
  Organism + `Sample Number` ~ list(`Sample Number`, NULL)))
@

The deletion of ``Sample Number'' is accomplished by the assignment of \code{NULL}, as usual in lists.
Instead of \code{+} almost all other operators could be used, and one could also write \code{c(Organism, `Sample Number`)} on the left side, which might be more intuitive.
If \code{map\_metadata()} is called without a mapping, it ``cleans'' the metadata by removing empty entries (by default including those that only contain \code{NA} values) and converting factors to character vectors.

But we have not yet stored an \proglang{OPMS} object with the cleaned metadata.
This could be done using \code{example.opm <- map\_metadata(example.opm, ...)}.
In that case, however, direct assignment would also be possible:

<<label=OPMS.clean.metadata, results=hide, width=8>>=
metadata(example.opm) <- Organism + `Sample Number` ~ 
  list(`Sample Number`, NULL)
metadata(example.opm)
@

Assigning \code{NULL} to a metadata entry would remove that entry.
We can achieve the same using an expression object:

<<label=metadata.expression, results=hide, width=8>>=
metadata(example.opm) <- to_metadata(csv_data(example.opm))[, 
  c("Strain Name", "Sample Number")] # reset
metadata(example.opm)
metadata(example.opm) <- expression(Organism <- `Sample Number`,
  rm(`Sample Number`))
metadata(example.opm)
@

Here, the assignment targets (names within the metadata) are specified directly using just the \code{<-} operator.
Apparently, arbitrarily complex code could be put in such a metadata-modifying expression.

All metadata would be cleared by assigning an empty list, without specifying a key:

<<label=empty.metadata, results=hide, width=8>>=
metadata(example.opm, "Organism") <- NULL
metadata(example.opm)
metadata(example.opm) <- list()
metadata(example.opm)
@

So keep in mind that formulas and expressions are very flexible for modifying metadata entries.
They would allow for any other operation (such as numerical calculations) provided it can be applied to the selected predefined metadata content.
The replacement function can also be used to copy metadata between \proglang{OPM} and/or \proglang{OPMS} objects.

Metadata can also be assigned specifically for subsets of \proglang{OPMS} objects, using the indexed assignment available for those objects:

<<label=assign.metadata, results=hide, width=8>>=
metadata(example.opm[2]) <- list(Organism = "Elephas maximus",
  Size = "3 meters")
metadata(example.opm)
metadata(example.opm[2]) <- list()
metadata(example.opm)
@


Readers may have noted that \code{metadata()} always returns a list, not a data frame.
This is because metadata need not contain the same entries, even within a single \proglang{OPMS} object, and can be nested.
It is possible, however, to get the metadata as data frame by using \code{to\_metadata()}.
Missing entries would then be filled with \code{NA} values, and nested metadata entries would yield data-frame columns of the mode ``list''.
This might or might not be suitable for further processing.
For statistical analysis, the appropriate way is to extract only those metadata entries that are present in \textit{all} \proglang{OPMS} elements, and usually also only those that are not themselves lists.
Methods such as \code{extract()} are based on this principle.


The following code, making use of the \code{metadata.example} data frame generated above, adds a new metadata entry with the key ``Character'' containing the integer values from the metadata entry called ``Integer'' converted to character mode
It then includes a new metadata entry with the key ``Times 10'' containing the entry ``Integer'' multiplied by 10.

<<label=include.metadata.II, results=hide, width=8>>=
example.opm <- include_metadata(example.opm, md = metadata.example)
metadata(example.opm)
example.opm <- map_metadata(example.opm, Character ~ as.character(Integer))
metadata(example.opm)
example.opm <- map_metadata(example.opm, `Times 10` ~ (Integer * 10))
metadata(example.opm)
@

Note that \code{map\_metadata()} can also be used with character vectors as mapping objects.
Making use again of the exemplar generated above, the key \textit{Colour} could be changed to \textit{Colony colour} as follows:

<<label=metadata.chars, results=hide, width=8>>=
example.opm <- include_metadata(example.opm, md = metadata.example)
md.map <- metadata_chars(example.opm, values = FALSE)
md.map
@

This yields a character vector including itself as \code{names} attribute, thus implying an identity mapping.
Next the new labels will be defined and will then be exchanged with the old ones using \code{map\_metadata()}.

<<label=map.metadata.II, results=hide, width=8>>=
md.map["Colour"] <- "Colony colour"
example.opm <- map_metadata(example.opm, md.map, values = FALSE)
metadata(example.opm)
@

The keys should have been changed to \textit{Colony colour} now but the values should have remained unaffected.
In addition to mapping based on character vectors, a mapping function could also have been used.
By setting their argument \code{values} to \code{TRUE}, the functions \code{metadata\_chars()} and \code{map\_metadata()} could be used as well to modify values instead of key.
For instance, assume any entries ``red'' in the field denoted \textit{Colony colour} should be changed to ``green'':

<<label=map.metadata.III, results=hide, width=8>>=
md.map <- metadata_chars(example.opm, values = TRUE)
md.map
md.map["red"] <- "green"
example.opm <- map_metadata(example.opm, md.map, values = TRUE)
metadata(example.opm)
@

This command will transform all entries in the table with the value "red" to "green".
Other values, as well as the keys, should be unaffected.

Frequently metadata entries will be used as factors in statistical models.
This always requires that the chosen metadata entry is present in all considered \proglang{OPM} object and sometimes requires that entries have to be combined.
For instance, for setting up a \textit{cell-means model} (see Section~\ref{methods group-means} and Section~\ref{application group-means} for further details), factors used for defining the groups of interest have to be merged. 
This might already be done during the initial step when setting up the metadata data frame \textit{before} including the metadata into an \proglang{OPM} or \proglang{OPMS} object using \code{include_metadata()}. 
Here, the function \code{interaction()} could be used to concatenate columns (but it should be taken into account that metadata entries should better not be represented as factors).
As a result, two metadata entries would be merged into a single one:

<<label=merge.metadata.I, results=hide, width=8>>=
metadata.example$Colour.Position <- as.character(interaction(
  metadata.example$Colour, 
  metadata.example$Position, sep = ".", drop = TRUE))
@
 
This is not recommended, however, unless all statistical comparisons of interest, or at least the group definitions of interest, were already known at this stage.
Even more tedious would be to go back to the initial metadata compilation add a later stage.
Using the metadata mapping functions, metadata entries can instead by merged at any time \textit{after} including them into an \proglang{OPM} or \proglang{OPMS} with \code{include_metadata()}.
For instance, the following code operates directly in the \proglang{OPMS} object, merging the . ``Colony colour'' (which had previously been renamed from ``Colour'', see above) and ``Integer'' entries into a new one:

<<label=merge.metadata.II, results=hide, width=8>>=
metadata(example.opm) <- Col.Int ~ paste(`Colony colour`, Integer, sep = ".")
metadata(example.opm)
@

As result, a new metadata entry named ``Col.Int'' is created with the general string concatenation tool \code{paste()}.


\subsection[Aggregating data by estimating curve parameters]{Aggregating data by estimating curve parameters}\label{application aggregating}

As mentioned above, the package brings along an \proglang{OPM} object, named \code{vaas\_1}, containing a full 96-well plate, aggregated data (curve parameters), and metadata:

<<label=load.data, results=hide>>=
data(vaas_1)
vaas_1
@

In the \pkg{opm} manual and help pages, the functions relevant for data aggregation are contained in a family called ``aggregation-functions'' with according cross-references.
Primarily \code{do\_aggr()} should be used for aggregation because it generates the kinds of objects that allow for the predefined work flows.
\code{vaas\_1} already contains aggregated data but we will re-calculate some for demonstration purposes.
For invoking the fast estimation method, use:

<<label=aggregation, results=hide, width=8>>=
vaas_1.reaggr <- do_aggr(vaas_1, boot = 100, method = "opm-fast")
@

This will only estimate two of the four parameters, namely A and AUC.
(Screen messages output by \code{boot.ci()} might be annoying but can usually be ignored.)
Information about the data aggregation settings is available \textit{via} \code{aggr\_settings()}:

<<label=aggregation.settings, results=hide>>=
aggr_settings(vaas_1)
aggr_settings(vaas_1.reaggr)
@

and the aggregated data can be extracted as a matrix \textit{via} \code{aggregated()}, e.g.:

<<label=aggregated, results=hide>>=
summary(aggregated(vaas_1))
summary(aggregated(vaas_1.reaggr))
@

The default settings of \code{do\_aggr()} includes 100-fold bootstrapping of the data to obtain confidence intervals.
As this is a time-consuming intensive process (particularly if \pkg{grofit} is used), it may be split over several cores on a multi-core machine if \code{mclapply()} from the \pkg{parallel} \proglang{R} package can be run with more than one core, which is possible on all operating systems except for Windows.

One can also specify different spline fitting methods using \code{method = "spline"}, which is the recommended setting (for historical reasons, it is not the default).
Options such as the spline type, the number of knots used for the spline and other options for the splines can be easily set using the function \code{set\_spline\_options} (which can only be used in conjunction with \code{method = "spline"}).
To essentially reproduce the results from \code{method = "grofit"} we could use smoothing splines (and for the sake of computing time in this vignette we only use 10 bootstrap replicates to compute confidence intervals for the parameter estimates):
<<label=smoothing.splines, results=hide>>=
op <- set_spline_options(type = "smooth.spline")
vaas_1.aggr2 <- do_aggr(vaas_1, boot = 10, method = "spline", options = op)
@
Other spline types can be specified \textit{via} the \code{type} argument in the function \code{set\_spline\_options}.
But the defaults have been optimized for PM data.


\subsection[Manipulation of OPM and OPMS data]{Manipulation of \proglang{OPM} and \proglang{OPMS} data}\label{application manipulation}

In the \pkg{opm} manual and help pages, the functions relevant for retrieving information contained in \proglang{OPM} or \proglang{OPMS} objects are included in a family called ``getter-functions'' with according cross-references.

For instance, the user may wish to select specific wells from the input plates, which are present in a 96-well layout, numbered from A01 to H12.
The function \code{dim()} provides the dimensions of an \proglang{OPMS} object as a three-element vector comprising (i) number of contained \proglang{OPM} or \proglang{OPMA} objects, (ii) the number of time points (of the first contained plate; these values need not be uniform within an \proglang{OPMS} object), and (iii) the number of wells (which must be uniform within an \proglang{OPMS} object).

To extract, for example, only the data from wells G11 and H11 together with the negative-control well A01 from the dataset \code{vaas\_et\_al} the bracket operator defined for the \proglang{OPMS} class has to be invoked as follows:

<<label=data.vaas.small, results=hide, width=10>>=
data("vaas_et_al", package = "opmdata")
vaas.small <- vaas_et_al[, , c("A01", "G11", "H11")]
dim(vaas.small)
@

\proglang{R} users should be familiar with this subsetting style, which was modelled after the style for multidimensional arrays, even though the internal representation is quite different.
Following the \code{dim()} function, in the first indexing position the plates, in the second the time points, and in the third position the wells are selected.
Moreover, in the second indexing position lists could be used, and in the third indexing position a formula could be applied.
This allows for creating sequences of well coordinates as, e.g., in \code{vaas\_et\_al[, , ~c(A08:B02, B05)]}, which would select eight wells.

After metadata have been added and adapted (see Section~\ref{application metadata}), \proglang{OPM} and \proglang{OPMS} objects can be queried for their content.
Specialized infix operators \code{\%k\%} and \code{\%q\%} (for \code{\%K\%} and \code{\%Q\%} see \code{?`\%K\%`} and \code{?`\%Q\%`}, respectively) have been modelled in analogy to \proglang{R}'s \code{\%in\%} operator.
The user may be interested whether an \proglang{OPM} or \proglang{OPMS} object contains a specific value associated with a specific metadata key, or the key associated with any value, or combinations of keys and/or values.
\code{\%k\%} allows the user to search in the metadata keys.
The user can test whether all given keys are present as names of the metadata.
\code{\%q\%} tests whether all given query keys are present as names of the metadata and refer to the same query elements.

Some examples using \code{vaas\_et\_al} are given in the following.
This \proglang{OPMS} object contains a metadata key \textit{Experiment} with the three possible values \textit{Time series}, \textit{First replicate}, and \textit{Second replicate}, and a metadata key \textit{Species} with  either \textit{Escherichia coli} or \textit{Pseudomonas aeruginosa} as values.

Examples for questions that could be asked on these metadata are given in the following.
Which plates within \code{vaas\_et\_al} have \textit{Experiment} as metadata key?

<<label=query.metadata.k.I, results=hide>>=
"Experiment" %k% vaas_et_al
vaas_et_al %k% "Experiment" # equivalent
vaas_et_al %k% ~ Experiment # equivalent
(~ Experiment) %k% vaas_et_al # equivalent, parentheses needed
@

Note that the arguments can be swapped and that a formula can be used.
Next, which plates within \code{vaas\_et\_al} have \textit{Experiment} and \textit{Species} as metadata key?

<<label=query.metadata.k.II, results=hide>>=
c("Experiment", "Species") %k% vaas_et_al
vaas_et_al %k% ~ c(Experiment, Species) # equivalent
@

The formula method works by evaluating the right side of the formula in the context of the metadata entries and reporting whether or not this yielded an error.
For this reason, \code{vaas\_et\_al \%k\% ~ Experiment + Species} would fail because there is no \code{+} operator for character strings.

Which plates within \code{vaas\_et\_al} have \textit{Experiment} and \textit{Species} as metadata key with the respective values \textit{First replicate} and \textit{Escherichia coli}?

<<label=query.metadata.q.I, results=hide>>=
c(Experiment = "First replicate",
  Species = "Escherichia coli") %q% vaas_et_al
vaas_et_al %q% ~ Experiment == "First replicate" & 
  Species == "Escherichia coli"
@

Again the two solutions are equivalent, but note the differences in the syntax that has to be used.
The formula method allows, in principle, for arbitrarily complex expressions.

Which plates within \code{vaas\_et\_al} have \textit{Species} as metadata key associated with the value \textit{Escherichia coli} or the value \textit{Bacillus subtilis}?

<<label=query.metadata.q.II, results=hide>>=
list(Species = c("Escherichia coli", "Bacillus subtilis")) %q% vaas_et_al
vaas_et_al %q% ~ Species %in% c("Escherichia coli", "Bacillus subtilis")
@

In addition to conducting queries with alternatives, using lists as queries would also allow for nested queries (as the metadata entries could also be nested).
Within formulas, nested keys should be separated by the \code{\$} operator.

The results of these infix operators are reported as logical vector with one value per plate; the usual \proglang{R} functions such as \code{all()}, \code{any()} or \code{which()} could be applied to work on these vectors.
They could also be used directly as the first argument of the bracket operator for \proglang{OPMS} objects to create subsets:

<<label=query.metadata.q.III, results=hide>>=
vaas.e.coli.1 <- vaas_et_al[c(Experiment = "First replicate",
  Species = "Escherichia coli") %q% vaas_et_al]
summary(vaas.e.coli.1)
rm(vaas.e.coli.1) # tidy up
@

Alternatively, the user may wish to subset a certain part of the data set using the function \code{subset()}, which is based on these kinds of querying for metadata keys and their values.
Prior to this, the user could check the keys of the metadata:

<<label=check.metadata.key, results=hide>>=
metadata_chars(vaas_et_al, values = FALSE)
@

The values in the metadata could be obtained by using \code{values = TRUE}.
Additionally, the user can check the values of special keys in the metadata:

<<label=check.metadata.values, results=hide>>=
metadata(vaas_et_al, "Species")
@

The resulting vectors could then also be used for mapping old metadata keys or values to novel ones (for details see Section~\ref{application metadata}).

The presented plotting results of \code{xy\_plot()} and \code{level\_plot()} (see Section~\ref{application plotting}) show selected subsets of \code{vaas\_et\_al}.
In our example below, the function \code{subset()} extracts the plates which contain the value \textit{First replicate} in the metadata key \textit{Experiment} and the value \textit{6} in the key \textit{Plate number}, resulting in one representative technical repetition and thus four plates (because four strains were involved) from the data set \code{vaas\_et\_al}:

<<label=subset, results=hide>>=
vaas.1.6 <- subset(vaas_et_al,
  query = list(Experiment = "First replicate", 'Plate number' = 6))
summary(vaas.1.6)
@

Providing the desired combination of metadata keys and values as a list offers much flexibility, and using a formula would offer a maximum of flexibility, but other approaches are also implemented.
The selection of plates could be based on the presence of keys only (like \code{\%k\%} described above; it makes not much sense for \code{vaas\_et\_al} whose plates are uniform regarding the keys), and/or use nested queries (like \code{\%q\%} with a list described above; makes of course more sense if the metadata contain nested entries).

The \code{subset()} function also has a ``time'' argument that allows one to create a subset containing only the time points that were common to all plates.
This is useful because deviations regarding the overall measurement hours might exist.
See the manual for details, using \code{help(`[`, package = "opm")}.

In addition to plate-wise querying and subsetting of \proglang{OPMS} objects, a number of conversion functions for selected content of all plates have been implemented.
The \pkg{opm} manual and help pages list them in a family of functions called ``conversion-functions'' with according cross-references.

For instance, the user may wish to explore the aggregated curve parameters (lag phase $\lambda$, steepness of the slope $\mu$, maximum curve height A, and area under the curve AUC).
These may be exported either as matrix or data frame using \code{extract()}:

<<label=extract.simple, results=hide>>=
vaas.mu <- extract(vaas_et_al, dataframe = TRUE,
  as.labels = NULL, subset = "mu")
@

To extract also the full or partial set of metadata, it is sufficient to add a list of desired metadata:

<<label=extract.complex, results=hide>>=
vaas.mu <- extract(vaas_et_al, dataframe = TRUE,
  as.labels = list("Experiment","Number of sample time point",
    "Plate number", "Slot", "Species", "Strain", "Time point in min"),
  subset = "mu")
@

This only works if this meta-information is present for the plates under study.
Once a data frame is exported, these metadata will be contained in additional columns; once a matrix is exported, they will be used to construct the row names.
The metadata could also be selected using a formula; see the help pages for details, particularly \code{?metadata}.
The default curve parameter returned by \code{extract()} can be set with \code{opm\_opt(curve.param = ...)}.

Finally, note that methods for a variety of generic \proglang{R} functions such as \code{unique}, \code{sort}, \code{duplicated}, \code{anyDuplicated} and \code{merge} are available for \proglang{OPMS} objects.
As specified using \code{sort(by = ...)}, sorting can be done based on selected metadata or on \code{csv_data()} entries such as the setup time.
The latter is of use in conjunction with the \code{merge} method, which is able to concatenate \proglang{OPM} objects from subsequent runs of the same plate.
Enter \code{help(sort, package = "opm")} and \code{help(merge, package = "opm")} at the \proglang{R} prompt for details.


\subsection[Plotting functions for raw data]{Plotting functions for raw data}\label{application plotting}

In the \pkg{opm} manual and help pages, the functions relevant for plotting are contained in a family called ``plotting-functions'' with according cross-references.
The function \code{xy\_plot()} displays the respiration curves as such (see Figure~\ref{fig:xy_plot}).
In our example the selected \proglang{OPMS} object \code{vaas.1.6} is the subset of the dataset \code{vaas\_et\_al} constructed in Section~\ref{application manipulation}:

<<label=xy.plot, fig=FALSE, width=8>>=
xy_plot(vaas.1.6, main = "E. coli vs. P. aeruginosa",
  include = list("Species", "Strain"))
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, width=18, height=12>>=
print(xy_plot(vaas.1.6, main = "E. coli vs. P. aeruginosa",
  include = list("Species", "Strain")))
@
}
\caption{
\label{fig:xy_plot}
PM curves from the 6th technical repetition of the first biological repetition plotted using \code{xy\_plot()} and by default arranged according to the factual plate layout (see \citep{vaas} for the difference between technical and biological repetitions).
The respective curves from all four strains are superimposed; the affiliation to each strain is indicated by colour (see the legend).
The x-axes show the measurement time in hours, the y-axes the measured colour intensities in OmniLog\textregistered \ units.
}
\end{figure}

Using the argument \code{main}, the user can include a main title in the plot; if it is omitted, by default the title is automatically constructed from the plate type.
Likewise, the well coordinates are automatically converted to substrate names (details can be set using additional arguments).
The content of the legend (mainly a description of the assignment of the colours to the curves) is also determined automatically.

The argument \code{include} refers to the metadata and allows the user to choose which entries should be used for assigning curve colours and accordingly be included in the legend.
Character vectors, lists and formulas are allowed as \code{include} argument.
See Section~\ref{application metadata} and \code{?metadata} in the help pages for details.
In the example the combination of species and strain is used, yielding four distinct colours.
If \code{include} is not used, the colours are assigned per plate.
Several predefined colour palettes are available in \pkg{opm} (accessible \textit{via} \code{select_colors()}) with a maximum of 24 distinct colours.
If more colours were needed, the user should set up a larger own colour vector and pass it as the argument \code{col} to \code{xy_plot} or preferably use \code{opm\_opt(colors = ...)}.

The plotting of sub-panels (see Figure~\ref{fig:xy_plot_2}) works as described above; the only difference is the previous manipulation of the dataset:

<<label=xy.plot.II, fig=FALSE, width=8>>=
xy_plot(vaas.1.6[, , c("A01", "G11", "H11")],
  main = "E. coli vs. P. aeruginosa", include = list("Species", "Strain"))
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, width=9, height=6>>=
print(xy_plot(vaas.1.6[, , c("A01", "G11", "H11")],
  main = "E. coli vs. P. aeruginosa",
  include = list("Species", "Strain")))
@
}
\caption{
\label{fig:xy_plot_2}
Selected PM curves from the 6th technical repetition from the first biological repetition plotted using \code{xy\_plot()}.
The respective curves from all four strains are superimposed, the affiliation to each strain indicated by colour (see the legend).
The x-axes show the measurement time in hours, the y-axes the measured colour-value units.
}

\end{figure}

The function \code{level\_plot()} (see Figure~\ref{fig:level_plot}) provides false-colour level plots from the raw respiration measurements over time:

<<label=level.plot.I, results=hide, fig=FALSE, width=8>>=
level_plot(vaas.1.6, main = "E. coli vs. P. aeruginosa",
  include = list("Species", "Strain"))
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, width=18, height=12>>=
print(level_plot(vaas.1.6, main = "E. coli vs. P. aeruginosa",
  include = list("Species", "Strain")))
@
}
\caption{
\label{fig:level_plot}
Visualization of PM curves using the function \code{level\_plot()}.
Each respiration curve is displayed as a thin horizontal line, in which the curve height as measured in colour-value units is represented by color intensity (darker parts indicate higher curves).
The x-axes correspond to the measurement time in hours.
}
\end{figure}

Again, a main title can be set explicitly.
Furthermore, the argument \code{include} again refers to the metadata and allows the user to choose the information to be included in the header for annotating the plates.
In the example the combination of species and strain is used.
The default colour palette used can by modified with \code{opm\_opt(color.borders = ...)}.


\subsection[Plotting the aggregated data]{Plotting the aggregated data}\label{application plotting-aggregated}

The function \code{heat\_map()} (see Figure~\ref{fig:heat_map}) provides false-colour level plots in which both axes are rearranged according to clustering results.
In the context of PM data, it makes most sense to apply it to the estimated curve parameters.
This \pkg{opm} function is a wrapper for \code{heatmap()} from the \pkg{stats} and \code{heatmap.2()} from the \pkg{gplots} package with some adaptations to PM data.
For instance, row groups can be automatically constructed from the metadata.

The function \code{heat\_map()} could be applied to matrices or data frames constructed using the helper function \code{extract()}, but it is more convenient to apply it directly to \proglang{OPMS} objects:

<<label=heat.map.I, results=hide, fig=FALSE, width=10>>=
vaas.1.6.A <- heat_map(vaas.1.6, as.labels = "Strain",
  as.groups = "Species")
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=6>>=
heat_map(vaas.1.6, as.labels = "Strain", as.groups = "Species")
@
}
\caption{
\label{fig:heat_map}
Visualization of the clustered results from the curve parameter maximum height (A) for each substrate using the function \code{heat\_map()}.
The x-axis corresponds to the substrates clustered according to the similarity of their values over all plates; the y-axis corresponds to the plates clustered to the similarity of their values over all substrates.
As row labels, the strain names were selected (argument \code{as.labels}), whereas the species affiliations was used to assign row group colours (bars at the left side, argument \code{as.groups}).
The central rectangle is a substrate $\times$ plate matrix in which the colours represent the classes of values.
The default colour setting uses topological colours, with deep violet and blue indicating the lowest values and light brown indicating the highest values, but another colour palette could also be chosen by the user.
The default can by set with \code{opm\_opt(hm.colors = ...)}.
}
\end{figure}


The function \code{radial\_plot()} is able to plot numeric values as distances from the center of a circular field in directions defined by angles in radians.
Some selection of wells should usually be applied beforehand for these plots to be useful.
Figure~\ref{fig:radial_plot} provides an example of such a visualization.
The parameter maximum height (A) is plotted for the wells A01 to A05 and A10 from dataset \code{vaas\_4}.
Note also that the values for positioning the upper-left corner of the legend are oriented according to the axes of the plot.
Hence, if the legend should be placed in the lower left part of the figure, negative values for x and y would be necessary.
The code is as follows:

<<label=radial.plot.I, results=hide, fig=FALSE, width=10>>=
radial_plot(vaas_4[, , c(1:5, 10)], as.labels = list("Species", "Strain"),
  x = 150, y = 200)
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=6>>=
radial_plot(vaas_4[, , c(1:5, 10)], as.labels = list("Species", "Strain"),
  x = 150, y = 200)
@
}
\caption{
\label{fig:radial_plot}
Comparison of point estimates for the parameter maximum height (A) observed from four strains, using \code{radial\_plot()}.
Shown are the results for estimating the maximum height of the single curves from wells A01 to A05 and A10.
}
\end{figure}


The function \code{ci\_plot()} is able to visualize point estimates and corresponding 95\% confidence intervals for the parameters, derived \textit{via} bootstrapping during aggregation of raw kinetic data into curve parameters, or, in conjunction with \code{extract()}, from plate groups defined by the metadata.
Thereby the bracket operator as described above (see Section~\ref{application manipulation}) facilitates the selection of subsets of interest. 

Figure~\ref{fig:ci_plot} provides an example of such a visualization.
The parameter maximum height (A) is plotted for the three wells A01 (Negative Control), A02 (Dextrin) and A03 (D-Maltose) from one plate (the sixth plate of the first biological repetition from dataset \code{vaas_et_al}).
The code is as follows:

<<label=ci.plot.I, results=hide, fig=FALSE, width=10>>=
ci_plot.legend <- ci_plot(vaas.1.6[, , c("A01", "A02", "A03")],
  as.labels = list("Species", "Strain"), subset = "A",
  legend.field = NULL, x = 170, y = 3)
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=6>>=
ci_plot(vaas.1.6[, , c("A01", "A02", "A03")], as.labels = list("Species", "Strain"), subset = "A", legend.field = NULL, x = 170, y = 3)
@
}
\caption{
\label{fig:ci_plot}
Comparison of point estimates and their 95\% confidence intervals for the parameter maximum height (A) observed from four strains, using \code{ci\_plot()}.
Shown are the results for estimating the maximum height of the single curves on the three wells A01 (Negative Control), A02 (Dextrin) and A03 (D-Maltose) as indicated by the sub-plot titles. Point estimates that have no overlapping confidence intervals are regarded to be significantly different.
But note that here the confidence intervals only indicate the uncertainty in parameter estimation from single curves.
}
\end{figure}


Furthermore, the helper function \code{extract()} (more specifically, its data-frame method) can group curve parameters from \proglang{OPMS} objects according to selected metadata and calculate according point estimates (means) and confidence intervals.
It can also apply normalisation beforehand, which might frequently be necessary to more easily recognize biological differences; see Section~\ref{methods plotting-aggregated}.

After the extraction of the values together with necessary metadata (argument \code{as.labels}) in a first call to \code{extract()}, the resulting data frame can be treated by \code{extract()} again for generating another data frame with numeric values grouped according to the \code{as.groups} argument and optionally normalisation applied, as triggered \textit{via} the argument \code{norm.per}.
The first data frame would be created as follows:

<<label=extract.dataframe, results=hide, fig=FALSE, width=10>>=
x <- extract(vaas_et_al, as.labels = list("Species", "Strain"),
  dataframe = TRUE)
@

For a better understanding of the following secondary applications of \code{extract()} it is highly recommended to take a look at the results from plotting the data with \code{ci\-plot()} and also at structure of the created data frames.

Using \code{norm.per = "none"} causes normalisation to be omitted.
If \code{as.groups = TRUE} is used, all metadata that have been included in the first data frame are used to determine the groups.
The result is shown in Fig~\ref{fig:ci_plot_groups}, after a further selection of columns from the second data frame to be passed to \code{ci\_plot()}.

<<label=ci.plot.II, results=hide, fig=FALSE, width=10>>=
# without normalisation
y <- extract(x, as.groups = TRUE,  norm.per = "none")
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 350, y = 0)
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=8>>=
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 350, y = 0)
@
}
\caption{
\label{fig:ci_plot_groups}
Comparison of mean point estimates and their 95\% confidence intervals, computed with \code{extract()} over groups defined by the ``Species'' and ``Strain'' metadata entries, for the parameter maximum height (A) observed from four strains, using \code{ci\_plot()}.
Shown are the results on the three wells A01 (Negative Control), A02 (Dextrin), A03 (D-Maltose), A04 (D-Trehalose) and A10 (Positive Control) as indicated by the sub-plot titles.
Normalisation was not used for this plot.
Point estimates that have no overlapping confidence intervals are regarded to be significantly different.
Compare this with Figure~\ref{fig:ci_plot_norm}.
}
\end{figure}

Normalisation can be applied by subtracting plate means (\code{norm.per = "row"}).
Per default, this would subtract the mean of each plate from each of its values (over all wells of that plate).
Alternatively, well means can be subtracted (\code{norm.per = "column"}).
Per default, this would subtract the mean of each well from each of its values (over all plates in which this well is present).
Division instead of subtraction is also possible (\code{subtract = FALSE}).

<<label=normalisation, results=hide, fig=FALSE, width=10>>=
# normalisation by plate means (figure not shown)
y <- extract(x, as.groups = TRUE,  norm.per = "row")
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 150, y = 0)

# normalisation by well means (figure not shown)
y <- extract(x, as.groups = TRUE,  norm.per = "column")
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 150, y = 0)
@

Moreover, \textit{via} \code{norm.by} it is possible to use one to several selected wells or plates for the calculation of the means used for normalisation. 
With \code{direct = TRUE} even directly entered numeric values can be used for normalisation purposes. 
See Figure~\ref{fig:ci_plot_norm} for an example of plotted confidence intervals obtained from data normalized by subtracting the value of well A10 (``Positive Control''). 
Note that due to the structure of the data frame \code{norm.per = "row"} in combination with the \code{norm.by} argument has to be used.


<<label=norm.well.A10, results=hide, fig=FALSE, width=10>>=
# normalisation by subtraction of the well means of well A10 only
y <- extract(x, as.groups = TRUE,  norm.per = "row", norm.by = 10,
  subtract = TRUE)
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 0, y = 0)
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=8>>=
ci_plot(y[, c(1:7, 13)], legend.field = NULL, x = 0, y = 0)
@
}
\caption{
\label{fig:ci_plot_norm}
Comparison of mean point estimates and their 95\% confidence intervals, computed with \code{extract()} over groups defined by the ``Species'' and ``Strain'' metadata entries, for the parameter maximum height (A) observed from four strains, using \code{ci\_plot()}.
Shown are the results on the three wells A01 (Negative Control), A02 (Dextrin), A03 (D-Maltose), A04 (D-Trehalose) and A10 (Positive Control) as indicated by the sub-plot titles.
Normalisation was done by subtracting the overall well means of well A10 (``Positive Control''). Point estimates that have no overlapping confidence intervals are regarded to be significantly different.
Compare this with Figure~\ref{fig:ci_plot_groups}.
}
\end{figure}

Additional example code on on visualizing curve parameters is available \textit{via} \code{opm\_files("examples")}.
It is indeed easy to conduct principal-component analysis (PCA) with matrices created with \code{extract()}.
Examples are given based on the \pkg{BiodiversityR} package \citep{Kindt2005}.


\subsection[Statistical comparisons of group means]{Statistical comparisons of group means}\label{application group-means}

To demonstrate the use of \code{opm\_mcp()}, the function for conducting multiple comparisons of group means directly on \proglang{OPMS} objects, we compare four distinct strains, each of which represented by ten replicates of GEN-III microplate measurements.
An experimental questions that could be addressed with these data might be ``Do these four bacteria differ in the mean value of curve parameter A on well G06'' (see Figure~\ref{fig:xy_plot_mcp})?
An according subset can be taken from the first biological replicate included in \code{vaas\_et\_al}:

<<label=data.vaas.subset, results=hide, width=8>>=
vaas.subset <- subset(vaas_et_al[, , "G06"], 
  list(Experiment = "First replicate"))
@

Now the dataset contains the four strains, each represented by the ten replicates shown in Figure~\ref{fig:xy_plot_mcp}. 

<<label=plot.vaas.subset, fig=FALSE, width=10>>=
xy_plot(vaas.subset, include = ~ Strain, neg.ctrl = FALSE,
  space = "right")
@

\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=6>>=
xy_plot(vaas.subset, include = ~ Strain, neg.ctrl = FALSE, 
  space = "right")
@
}
\caption{
\label{fig:xy_plot_mcp}
PM curves from the ten technical replicates of the first biological repetition plotted using \code{xy\_plot()}.
The respective curves from all four strains are superimposed; the affiliation to each strain is indicated by colour (see the legend).
The x-axes show the measurement time in hours, the y-axes the measured colour intensities in OmniLog\textregistered \ units.
}
\end{figure}

To solve the statistical question, we now perform a multiple comparison of group means using \code{opm\_mcp()}.
The groups to be compared (and to be selected from the metadata beforehand) are defined by the argument \code{model}.
The argument \code{m.type} specifies the type of model to be used for fitting, e.g., a linear model (\code{lm}), a generalized linear model (\code{glm}), or an analysis-of-variance model (\code{aov}).
\textit{Via} the argument \code{linfct} the user can define the type of contrast matrix to be used for the multiple comparison. 
In principle, the contrast matrix defines which group means should be compared and how.
In our example a Tukey-type contrast matrix is applied, indicating an all-against-all comparison. 
This results in a set of six two-sided pairwise comparisons between all the four strain means (all possible pairs).
A more detailed explanation of contrast matrices is given below.

<<label=opm.mcp.principle, results=hide, width=8>>=
vaas.subset.mcp <- opm_mcp(vaas.subset, model = ~ Strain, m.type = "aov",
  linfct = c(Tukey = 1))
@

This kind of \code{linfct} argument, a numeric vector, refers to the positions of the variables within \code{model}.
In that case the first and only term, ``Strain'', is selected.
The names of such a \code{linfct} object indicate the type of contrast used.
If names were missing, \code{opm_opt("contrast.type")} would be inserted.
The way \code{opm\_mcp()} converts \code{linfct} arguments can be explored using \code{output = "linfct"}:


<<label=opm.mcp.linfct, results=hide, width=8>>=
opm_mcp(vaas.subset, model = ~ Strain, m.type = "aov",
  linfct = c(Tukey = 1), output = "linfct")
@

(Similarly, the conversions applied to the \code{model} argument, if any, can be tested using \code{output = "model"}.)
But \code{linfct} can also be specified more explicitly, as detailed below.

Per default, \code{opm_mcp()} uses \code{glht()} from the package \pkg{multcomp} and returns an object of class \code{glht}.
As shown in Figure~\ref{fig:ci_plot_mcp}, the results of the performed statistical test can be plotted using the methods available for objects of that class (see \code{?multcomp::glht} for details).


<<label=plot.opm.mcp.linfct, fig=FALSE, width=8>>=
library(multcomp) # now needed
old.mar <- par(mar = c(3, 15, 3, 2)) # adapt margins in the plot
plot(vaas.subset.mcp)
par(old.mar) # reset to default plotting settings
@


\begin{figure}
\scalebox{1.225}{
<<fig=TRUE, echo=FALSE, width=8, height=3>>=
library(multcomp)
old.mar <- par(mar = c(3, 15, 3, 2))
plot(vaas.subset.mcp)
par(old.mar)
@
}
\caption{
\label{fig:ci_plot_mcp}
Comparisons of group means from well G06 between the four exemplar strains calculated with \code{opm\_mcp()} and the plotting method for the resulting object.
On the y axis the performed comparisons are indicated as differences of the groups, determining which differences of means are computed.
All pairwise comparisons are shown.
The filled black circle indicates the point estimator of difference between the mean of groups.
95\% confidence intervals for are indicated by horizontal bars and parentheses.
Note the differences between interpretation of this figure and the Figures obtained with \code{ci\_plot()} in Section~\ref{application plotting-aggregated}, as explained in the main text.
}
\end{figure}


The main results can be obtained as follows:

<<label=summary.opm.mcp, width=8>>=
mcp.summary <- summary(vaas.subset.mcp)
mcp.summary$model$call <- NULL # avoid some unnecessary output
mcp.summary
@

The interpretation of confidence intervals for differences of means is somewhat distinct from the interpretation of the confidence intervals for the point estimators for curve parameters as discussed in Section~\ref{application plotting-aggregated}.
In pairwise comparisons, if the 95\% confidence interval includes zero (dashed vertical lines in Figure~\ref{fig:ci_plot_mcp}) there is no significant difference between the group means.
Conversely, if zero is not included, a significant difference is indicated.
Furthermore, the more distant the 95\% confidence interval is from zero, the larger the biological effect size, i.e. the real difference between the groups. 
In the here shown example all group means of the curve parameter A are significantly different from each other (p < 0.001), except for the comparison of strains DSM 30083\textsuperscript{T} and DSM 1707 (Figure~\ref{fig:ci_plot_mcp}).

The last comparison showing the difference of mean of curve parameter A values of strain DSM 30083\textsuperscript{T} minus the mean of A values of strain DSM 18039 results 26.615 units. 
Therefore, the point estimator of this difference of specific group means is plotted at position 26.615 on the x-axis. 
That is, on average the A values from well G06 and Strain DSM 30083\textsuperscript{T} are 26.615 units larger than the A values of strain DSM 18039.
(The detailed numeric outcome would be obtained using \code{mcp.summary()} or \code{confint(vaas.subset.mcp)}).
Additionally, each point estimator for the difference of means comes with an 95\% confidence interval providing information about the statistical significance of the test, the effect size and the variability of the mean differences.

Note that effect sizes are not correlated with the sizes of the corresponding p-values.
In our example, the results from the statistical calculations indicate that all significant differences are also highly significant (p < 0.001).
But the position of the 95\% confidence interval indicates that the difference between strains DSM 18039 and 429SC1 (i.e, the effect size in the second comparison in Figure~\ref{fig:ci_plot_mcp}) is much larger than between strains DSM 30083\textsuperscript{T} and 429SC1 (smaller effect size in the third comparison).
For a meaningful biological interpretation of the results it is therefore highly recommended to not only take into account the p values but also the effect sizes.

For performing the comparisons of interest, the user has to provide a contrast matrix.
A contrast is defined as a linear combination of two or more factor level means (averages) whose coefficients add up to zero \citep{hochberg}. 
To demonstrate the principle of a contrast matrix, an all-against-all comparison (a ``Tukey''-type contrast) of four groups is performed using a toy-example. 

<<label=contrMat, width=8>>=
n <- c(10, 20, 30, 40)
names(n) <- paste("group", 1:4, sep = "")
contrMat(n, type = "Tukey")
@

The output table reads as follows.
In each line, a pair of group-wise comparisons is defined by the locations of the non-zero values.
For instance, in the first line, the 1 and -1 values indicate that the means of \code{group1} are subtracted from the means of \code{group2}.
The function \code{contrMat()} from \pkg{multcomp} (see \code{?multcomp::contrMat}) provides an overview of the predefined contrast types that can be used in the \code{opm\_mcp()} argument \code{linfct}.

In the example from above (see Figure~\ref{fig:ci_plot_mcp}), a ``Tukey''-type contrast was used to trigger the comparison of all groups against all others in the data set.
The underlying contrast matrix used to set up the contrasts for Figure~\ref{fig:xy_plot_mcp} can be viewed by entering

<<label=mcp.summary.linfct, width=8>>=
mcp.summary$linfct
@


Accordingly, the user is free to set up contrast matrices for \code{opm\_mcp()} that define the comparisons of interest.
However, first a model must be set up that defines the factors that determine the groups and thus the possibilities for comparisons.
As the next example, we will now compare the overall performance of the tested organisms on the first four wells A01 to A04. 
Although the user typically expects these wells to be in order in an \proglang{OPMS} object, this actually may have been changed by a previous well selection.
Moreover, details of the the implementation of the conversion of \proglang{OPMS} objects to data frames, and of reshaping these data frames, can be subject to change, which might also affect the order of factor levels within the final data passed to \code{glht()}.
Hence, it should be avoided to set up a contrast matrix fully by hand.
Instead, \code{opm\_mcp(output = "contrast")} yields one to several template contrast matrices, which are guaranteed to match the used \proglang{OPMS} object.
Such templates could the be further modified by the user.

For instance, the following output would contain a contrast matrix with all possible comparisons (because ``Tukey'' is used) for \code{Well} as factor variable in the correct order for the first four wells of \code{vaas_4}:

<<label=contrast.matrix.I, results=hide, width=8>>=
contr <- opm_mcp(vaas_4[, , 1:4], model = ~ Well, linfct = c(Tukey = 1),
  output = "contrast")
contr
@

The \code{contr} object is a named list of contrast matrices, with one matrix per factor selected.
An according call of the \code{opm_mcp()} function after selecting some comparisons of interest would then be:

<<label=mcp.wells, results=hide, width=8>>=
vaas4.mcp <- opm_mcp(vaas_4[, , 1:4], model = ~ Well, m.type = "lm",
  linfct = contr$Well[c(1:3, 6), ])
@


The correct set-up of the contrast matrix could be controlled after the fact by typing
<<label= summary.mcp.wells, width=8>>=
summary(vaas4.mcp)$linfct
@


As mentioned above, the outcome can be visualized using the \code{plot()} method for \code{glht} objects (see Figure~\ref{fig:opm_mcp_CI_plotII}).

\begin{figure}
\scalebox{0.9}{
<<fig=TRUE, echo=FALSE, results=hide, width=9, height=3>>=
old.mar <- par(mar = c(3, 20, 3, 2)) # adapt plotting settings
plot(vaas4.mcp)
par(old.mar) # reset plotting settings
@
}
\caption{
\label{fig:opm_mcp_CI_plotII}
Point estimates and 95\% confidence intervals in a manually defined comparison of group means for a specifically selected set of wells (A01 to A04) from the \code{vaas\_4} exemplar object.
The picture was obtained by running \code{opm\_mcp()} and then the plotting function for the resulting object.
Compare with Figure~\ref{fig:ci_plot_mcp}, where details on the axis annotation are given.
}
\end{figure}

Note that the \code{model} statement defines the group means available for comparisons. 
In the following example ``Species'' contains only two levels (``\textit{Pseudomonas aeruginosa}'' and ``\textit{Escherichia coli}''). 
Thus, irrespective of the stated contrast type, only one comparison is possible.

<<label=model.mcp, width=8>>=
vaas4.mcp <- opm_mcp(vaas_4, model = ~ Species, m.type = "lm",
  linfct = mcp(Species = "Dunnett"))
@

Finally, note that \code{opm\_mcp()} in an intermediary step reshapes the selected data into a ``flat'' data frame.
This object can be returned (and the multiple comparisons omitted) by using \code{output = "data"}:

<<label=mcp.output.data, results=hide, width=8>>=
vaas4.mcp <- opm_mcp(vaas_4, model = ~ Species + Strain,
  output = "data")
head(vaas4.mcp)
@

The resulting object might be of use in other analysis strategies, analogously to the function \code{flatten()}, which performs a similar reshaping for raw data.
See the \pkg{opm} manual for details, typing \code{?opm\_mcp} or \code{?flatten}.

For the special case of the above mentioned \textit{cell-means model} (see Section~\ref{application metadata} and Section~\ref{methods group-means}) it might be necessary to merge two or more metadata entries and generate a new one, whose levels (after automated conversion to a factor in a data frame) define the groups of interest:

<<label=data.G06, results=hide, width=8>>=
vaas.G06 <- vaas_et_al[, , "G06"]
metadata(vaas.G06)[114]
metadata(vaas.G06) <- Str.Exp ~ paste(Strain, Experiment, sep = ".")
metadata(vaas.G06)[114]
@

With the newly generated metadata entry \code{Str.Exp} that comprehends both \code{Strain} and \code{Experiment}, the multiple-comparison procedure can be conducted as follows:

<<label=mcp.G06, results=hide, width=8>>=
vaas.G06.mcp <- opm_mcp(vaas.G06, model = ~ Str.Exp, 
  linfct = c(Dunnett = 1))
@

The result is shown in Figure~\ref{fig:opm_mcp_CI_plot_cell-meansI}, visualized using \code{plot()} as described above.

\begin{figure}
\scalebox{0.9}{
<<fig=TRUE, echo=FALSE, results=hide, width=8, height=4>>=
old.mar <- par(mar = c(3, 22, 3, 1)) # adapt plotting settings
plot(vaas.G06.mcp)
par(old.mar) # reset plotting settings
@
}
\caption{
\label{fig:opm_mcp_CI_plot_cell-meansI}
Point estimates and 95\% confidence intervals in a Dunnett-type comparison of group means for a \textit{cell-means model} for the \code{vaas.G06} exemplar object.
In analogy to Figure~\ref{fig:opm_mcp_CI_plotII}, the picture was obtained by running \code{opm\_mcp()} and then the plotting function for the resulting object.
Compare also with Figure~\ref{fig:ci_plot_mcp}, where details on the axis annotation are given.
}
\end{figure}

Finally, besides the multiple comparison of single group means as described above, it is also possible to compare averages from several subgroups with a single other subgroup or averages from several other subgroups.
For example, the user may be interested in comparing the data shown in Figure~\ref{fig:opm_mcp_CI_plot_cell-meansI} at the level of groups that may contain different data sets as subgroups. 
When building a contrast matrix, keep in mind that the levels of the model-defining factor needs to match the columns of the contrast matrix, in order.
For this reason, it is advantageous to work with a template contrast matrix generated with \code{opm\_mcp()} from the object under study and check the positioning of its column names prior to any modification:

<<label=mcp.G06.output.contrast, results=hide, width=8>>=
contr <- opm_mcp(vaas.G06, model = ~ Str.Exp,
  linfct = c(Dunnett = 1), output = "contrast")$Str.Exp
colnames(contr)
@

The user is then free to choose other values than just 0 and 1 for the coefficients, provided that each contrast sums up to zero.
In the example below, the contrast matrix is reduced to three contrasts of interest, in which the values 0, -1/4 , 1/4, and 1 are used.
The reader might have noted that the ``First replicate'' entries are in columns 1, 3, 5 and 8, whereas the ``Second replicate'' entries are in columns 2, 4, 6 and 9 and the ``Time series'' entries are in column 7 of the object \code{contr}.
This information is sufficient to set up a correct contrast matrix for the following three contrasts of interest:

<<label=mcp.G06.user.def.contrasts, results=hide, width=8>>=
contr <- contr[1:3, ] # keeps the column names
rownames(contr) <- c(
  "First repl. - Second repl.",
  "First repl. - Time series",
  "DSM 1707 #1 - Second repl."
)
contr[1, ] <- c(1/4, -1/4, 1/4, -1/4, 1/4, -1/4, 0, 1/4, -1/4)
contr[2, ] <- c(1/4, 0, 1/4, 0, 1/4, 0, -1, 1/4, 0)
contr[3, ] <- c(0, -1/4, 1, -1/4, 0, -1/4, 0, 0, -1/4)
contr
vaas6.mcp <- opm_mcp(vaas.G06, model = ~ Str.Exp, m.type = "lm",
  linfct = mcp(Str.Exp = contr))
@

The resulting visualisation of this entirely user-defined contrast matrix is shown in Figure~\ref{fig:opm_mcp_CI_plot_cell-meansII}.

\begin{figure}
\scalebox{0.9}{
<<fig=TRUE, echo=FALSE, results=hide, width=8, height=3>>=
old.mar <- par(mar = c(3, 12, 3, 2)) # adapt plotting settings
plot(vaas6.mcp)
par(old.mar) # reset plotting settings
@
}
\caption{
\label{fig:opm_mcp_CI_plot_cell-meansII}
Point estimates and 95\% confidence intervals in a user defined comparison of group means for a \textit{cell-means model} for the \code{vaas.G06} exemplar object.
Like Figure~\ref{fig:opm_mcp_CI_plotII}, the picture was obtained by running \code{opm\_mcp()} and then the plotting function for the resulting object.
Compare also with Figure~\ref{fig:ci_plot_mcp}, where details on the axis annotation are given.
}
\end{figure}



\subsection[Discretization and phylogenetic data export]{Discretization and phylogenetic data export}\label{application discrete-phylogeny}

After calculating curve parameters and optionally generating a suitable subset, data can be discretized and optionally also exported for analysis with external phylogeny software.
In the \pkg{opm} manual and help pages, the functions relevant for either task are contained in the families ``discretization-functions'' and ``phylogeny-functions'' with according cross-references.
Much like \code{do\_aggr} for aggregation, \code{do\_disc} should be preferred for discretization.
By default it works on the A parameter (see Figure~\ref{fig:parameters}) but this can be modified.

Restricting the \code{vaas\_et\_al} example dataset to the two biological replicates yields an orthogonal dataset with 2$\times$10 replicates for each of the four strains for which we can calculate discretized parameters:

<<label=discretize, results=hide, width=8>>=
vaas.repl <- subset(vaas_et_al,
  query = list(Experiment = c("First replicate", "Second replicate")))
vaas.repl <- do_disc(vaas.repl)
@

Note that the resulting objects is an \proglang{OPMS} object with \proglang{OPMD} objects as elements.
Such objects contain discretized values, available \textit{via} \code{discretized()}, and the discretization settings used, which can be obtained using \code{disc\_settings()}.
This works much like \code{aggregated()} and \code{aggr\_settings()} explained above.
\code{disc\_settings()} also yields the computed discretization cutoffs.
The \code{subset()} function has a \code{positive} argument that allows one to create a subset containing only the wells that were positive in at least one plate or in all plates, as well as a corresponding \code{negative} argument.
The effect of either could be modified with \code{subset(invert = TRUE)}.
For example, the command \code{xy\_plot(subset(vaas_4, positive = "all"), neg.ctrl = NULL)} would plot only those wells in which all curves have been classified by k-means partitioning to yield a positive reaction.
See the manual for further details, using \code{help(subset, package = "opm")}.


\subsection[Discretization and export of text]{Discretization and export of text}\label{application discrete-text}

The \code{listing()} methods of the \proglang{OPMD} and \proglang{OPMD} classes create textual descriptions of the discretization results suitable for the direct inclusion in scientific manuscripts.

<<label=list.discretize, results=hide, width=8>>=
listing(vaas.repl, as.groups = NULL)
listing(vaas.repl, as.groups = list("Species"))
@

As usual, the results can be grouped according to specified metadata entries using the ``as.groups'' argument.
If this yields ambiguities (such as a negative reaction of the same well on one plate and a positive reaction on another plate), the result is accordingly renamed.
The ``cutoff'' argument can be used to define filters, keeping only those values that occur in a specified minimum proportion of wells.
See the manual for details, using \code{help(listing, package = "opm")}.

The \code{listing()} function returns a character vector or matrix with the \proglang{S3} class ``OPMD\_listing'' or ``OPMS\_listing'', allowing for a special \code{phylo\_data()} function that further formats these objects. Accordingly, the following code snippets

<<label=phylo.data.I, results=hide, width=8>>=
phylo_data(listing(vaas.repl, as.groups = NULL))
phylo_data(listing(vaas.repl, as.groups = list("Species")))
@

would yield character scalars better suitable for exporting into text files using \code{write}. It is also possible to generate \proglang{HTML} output, yielding formatted text. Try

<<label=phylo.data.II, results=hide, width=8>>=
phylo_data(listing(vaas.repl, as.groups = NULL, html = TRUE))
phylo_data(listing(vaas.repl, as.groups = list("Species"), html = TRUE))
@

and note that the \code{phylo\_data()} function has a ``html.args'' argument.
Textual \proglang{HTML} output supports most of the formatting instructions  for the output of \proglang{HTML} tables described below (see \ref{application discrete-table}).
Note particularly how formatting \textit{via} a \proglang{CSS} file works, as described in Section~\ref{application discrete-table}.

The default settings of \code{do\_disc()} imply exact k-means partitioning into three groups (``negative'', ``ambiguous'' and ``positive''), treating all contained plates together.
Let $A_1$ and $A_2$ be the maximum-height parameters from two curves $C_1$ and $C_2$, respectively, and let us assume that $A_1 \geq A_2$ holds.
The algorithm then guarantees that if $C_2$ is judged as positive reaction then $C_1$ is also judged as positive; if $C_2$ is weak then $C_1$ is not negative; if $C_1$ is negative then $C_2$ is negative; and if $C_1$ is weak then $C_2$ is not positive.
There are not many other things the algorithm guarantees.
Note particularly that always three clusters result by default (one can omit the middle cluster, i.e. the ``weak'' reactions), irrespective of the input data.
That is, additionally checking the curve heights and particularly the ``cutoffs'' entry obtained \textit{via} \code{disc\_settings()} should be mandatory.

The manual describes the other discretization approaches available in \pkg{opm}, such as using \code{best\_cutoff()} instead of k-means partitioning, and using subsets of the plates, specified using stored metainformation.
See \code{?do\_disc}.


\subsection[Discretization and export of tables]{Discretization and export of tables}\label{application discrete-table}

The \proglang{HTML} created by \pkg{opm} deliberately contains no formatting instructions.
Rather, it is possible (and recommended) to link it to a \proglang{CSS} file.
\proglang{CSS} (``Cascading Style Sheets'') is a style-sheet language used for defining the formatting of a document written in a markup language such as \proglang{HTML}.

As the generated \proglang{HTML} is richly annotated with ``class'' attributes, which not only provide information on the structure of the file but also on the depicted data, very specific formatting can be obtained just by modifying one to several associated \proglang{CSS} files.
For the following example, we set the default \proglang{CSS} file to be linked from the generated \proglang{HTML} to the file that comes with \pkg{opm}.

<<label=opm.css.file, results=hide, width=8>>=
opm_opt(css.file = grep("[.]css$", opm_files("auxiliary"), value = TRUE))
@

One could now easily create an \proglang{HTML} table from the discretized data and write it to a file:

<<label=opm.html.file, results=hide, width=8>>=
vaas.html <- phylo_data(vaas.repl, format = "html",
  as.labels = list("Species", "Strain"), outfile = "vaas.html")
@

A practical problem is that the resulting \proglang{HTML} file is linked to its \proglang{CSS} file with a fixed path.
The formatting would thus get lost once the \proglang{HTML} file was copied to another system, without a warning.
So users might want to copy the predefined \proglang{CSS} file to the working directory and set it as default:

<<label=wd.css.file, results=hide, width=8>>=
file.copy(grep("[.]css$", opm_files("auxiliary"), value = TRUE),
  "opm_styles.css", overwrite = TRUE)
opm_opt(css.file = "opm_styles.css")
@

The generated \proglang{HTML} would subsequently be linked to this file, and the two files could be distributed together.
The same mechanism works for text generation using \code{listing()} (see \ref{application discrete-text}).
In addition to the default CSS file, a complete list of the settings that can be modified with this function is available \textit{via} \code{?opm\_opt}.

Users who want to define their own \proglang{CSS} files can start with modifying the file shipped with \pkg{opm}.
Microsoft Windows users should consider that the path to the file must be provided in \proglang{UNIX} style, as obtained, e.g., using \code{normalizePath(x, winslash = "/")} if \code{x} is the path to the file.
This is according to World Wide Web standards and not determined by \pkg{opm}.

By default columns with measurement repetitions as specified using \code{as.labels} are joined together.
The \code{delete} argument specifies how to reduce the table: either not at all or keeping only the variable, parsimony-informative or non-ambiguous characters.
The legend of the table is as used in taxonomic journals such as the \textit{International Journal of Systematic and Evolutionary Microbiology} (\url{http://ijs.sgmjournals.org/}) but could also be adapted.
Users can modify the headline, add sections before the table legend, or before or after the table.
The title and the ``meta'' entries of the resulting \proglang{HTML} can also be modified.
The \code{phylo\_data()} methods have an auxiliary function, \code{html\_args}, which assists in putting together the arguments that determine the shape and content of the \proglang{HTML} output.
See the manual for further details, using \code{?html\_args}.

\subsection[Fine-tuning the discretization]{Fine-tuning the discretization}\label{application discrete-finetuning}

One can also conduct discretization step-by-step by using the functions \code{best\_cutoff()} or \code{discrete()} after extracting matrices from the \proglang{OPMS} object.
This offers more flexibility (such as additional discretization approaches, e.g. the creation of multiple-state characters) but is also more tedious than using \code{do\_disc()}.

<<label=prep.disc.data,results=hide, width=8>>=
vaas.repl <- subset(vaas_et_al,
  query = list(Experiment = c("First replicate", "Second replicate")))
vaas.repl <- extract(vaas.repl,
  as.labels = list("Species", "Strain", "Experiment", "Plate number"))
@

The A parameter (see Figure~\ref{fig:parameters}) can be discretized into (per default) 32 states using the theoretical range of 0 to 400 OmniLog\textregistered \ units (see Section~\ref{methods discrete-multistate}):

<<label=disc.data.I, width=12>>=
vaas.repl.disc <- discrete(vaas.repl, range = c(0, 400))
@

This yields (at most) 32 distinct character states corresponding to the 32 equal-width intervals within 0 and 400.
Exporting the data in \textit{extended \proglang{PHYLIP} format} readable by \proglang{RAxML} \citep{stamatakis} would work as follows:

<<label=phylo.data.III, width=10>>=
phylo_data(vaas.repl.disc, outfile = "example_replicates.epf")
@

The other supported formats are \proglang{PHYLIP}, \proglang{NEXUS} and \proglang{TNT} \citep{goloboff}.
For discretizing the data not in equally spaced intervals but into binary characters including missing data, or ternary characters with a third, intermediary state between "negative" and "positive" the gap mode of \code{discrete()} can be used:

<<label=disc.data.II, width=12>>=
vaas.repl.disc <- discrete(vaas.repl, range = c(120.2, 236.6), gap = TRUE)
@

Here the range argument provides not the overall boundaries of the data as before (at least as large as the real range), but the boundaries of a zone within the real range of the data corresponding to an area of ambiguous affiliation.
That is, values below 120.2 are coded as ``0'', those above 236.6 as ``1'', and those in between as ``?''.
The values used above were determined by k-means partitioning of the A values from the \code{vaas\_et\_al} dataset \citep{vaas}; there is currently no conclusive evidence that they can generally be applied.
The last command would result in the treatment of values within the given range as ``missing data'' (\code{NA} in \proglang{R}, ``?'' if exported).
To treat them as a third, intermediary character state, set \code{middle.na} to \code{FALSE}:

<<label=disc.data.III, width=10>>=
vaas.repl.disc <- discrete(vaas.repl, range = c(120.2, 236.6),
  gap = TRUE, middle.na = FALSE)
@

The three resulting states, coded as ``0'', ``1'' and ``2'' (in contrast to ``0'', ``?'' and ``1'' above) would have to be interpreted as ``negative'', ``weak'' and ``positive''.
Exporting the data in one of the supported phylogeny formats would work as described above.
If the \code{do\_disc()} function described above calls \code{discrete()}, then only in gap mode and with \code{middle.na} set to \code{TRUE}, yielding a vector or logical matrix.


\subsection[Accessing substrate information]{Accessing substrate information}\label{application substrates}

The \pkg{opm} package contains a number of functions suitable for accessing precomputed information on the substrates of wells and plates.
In the manual and help pages these functions are contained in the family ``naming-functions'' with according cross-references.
One usually would start a search by determining the exact spelling of an internally used name with \code{find\_substrate()}:

<<label=find.substrate.I, results=hide>>=
names <- find_substrate(c("Glutamine", "Glutamic acid"))
names
@

The results is a list containing character vectors with the results for each query name as values.
Surprisingly, nothing was found for ``Glutamic acid'' but several values for ``Glutamine''.
The default \code{search} argument is ``exact'', which is exact (case-sensitive) matching  of \textit{substrings} of the names.
One might want to use ``glob'' searching mode:

<<label=find.substrate.II, results=hide>>=
names <- find_substrate(c("L-Glutamine", "L-Glutamic acid"), "glob")
names
@

But with so-called wildcards, i.e. ``*'' for zero to many and ``?'' for a single arbitrary character the search is more flexible:

<<label=find.substrat.III, results=hide>>=
names <- find_substrate(c("*L-Glutamine", "*L-Glutamic acid"), "glob")
names
@

This fetches all terms that end in either query character string, and does so case-insensitively.
Advanced users can apply the much more powerful ``regex'' and ``approx'' search modes; see the manual for details, entry \code{?find\_substrate}.

Once the internally used names have been found, information on the substrates can be queried such as their occurrences and positions on plates:

<<label=find.positions, results=hide>>=
positions <- find_positions(names)
positions
@

This yields a nested list containing two-column matrices with plate names in the first and well coordinates in the second column.
References to external data resources for each substrate name can be obtained using \code{substrate\_info()}:

<<label=substrate.info, results=hide>>=
subst.info <- substrate_info(names)
subst.info
@

By default this yields CAS numbers, but MeSH, KEGG and Metacyc IDs have also been collected for the majority of the substrates.
Another use of \code{substrate\_info()} is to convert substrate names to lower case but protecting name components such as abbreviations or chemical symbols.
See the manual for further details, help page \code{?substrate\_info}.


\section[Discussion and conclusion]{Discussion and conclusion}

The high-dimensional sets of longitudinal data collected by the OmniLog\textregistered \ PM system call for fast and easily applicable (and extendable) data organisation and analysis facilities.
The here presented \pkg{opm} package for the free statistical software \proglang{R} \citep{r} features not only the calculation of aggregated values (curve parameters) including their (bootstrapped) confidence intervals, but also provides a rather complete infrastructure for the management of raw kinetic values and curve parameters together with any kind of meta-information of relevance for the user.

The spline estimation and parameter calculation in the data-aggregation step of has been optimized for the analysis of PM data.
One main issue in the spline-fitting procedure is the selection of suitable smoothing parameters.
The methods included in \pkg{opm} provide not only the basic framework \citep{vaas} based on methods from the \pkg{grofit} package \citep{kahm}, but also specifically adapted applications of  \code{smooth.spline} and the \pkg{mgcv} package \citep{Wood2003, eilers}

The analysis toolbox of the package includes the implementation of a fully automated estimation of whether respiration kinetics should be classified as either a ``positive'' or ``negative'' (absent) physiological reaction.
This dichotomization is apparently of high interest to many users of the OmniLog\textregistered \ PM system but would apparently be extremely biased as long as thresholds are chosen ad hoc and by eye.
Users should nevertheless be aware that loss of information is inherent to discretizing continuous data.

The \pkg{opm} package enables the user to produce highly informative and specialized graphical outputs from both the raw kinetic data as well as the curve-parameter estimates.
Moreover, the package provides simultaneous multiple comparisons of group means \citep{hothorn, bretz, hsu} with an interface specifically adapted to the typical PM data objects.
In combination with the functionality for annotating the data with meta-information and then selecting subsets of the data, straightforward analyses regarding specific analytical questions can be performed without the need to invoke other \proglang{R} packages.

But since the design of the \pkg{opm} objects is not intended to be limited to specific analysis frameworks, the \pkg{opm} package works as a data containment providing well organized and comprehensive PM data for further, more specialized analyses using methods from different \proglang{R} packages or other third-party software tools.
Particularly the generation of \proglang{S4} objects featuring a rich set of methods as containers for either single or multiple OmniLog\textregistered \ PM plates enables not only the transfer of raw kinetic data into \proglang{R} but also eases their further processing.
The complex data bundles can also be exported in \proglang{YAML} format, which is a human-readable data serialization format that can be read by most common programming languages and facilitates fast and easy data exchange between laboratories.
If a proper \proglang{YAML} parser was unavailable, its subset \proglang{JSON} could also be used.

These features render the \pkg{opm} package the first comprehensive toolbox for the management and a broad range of analyses of OmniLog\textregistered \ PM data.
Its usage requires some familiarity with \proglang{R}, but is otherwise intuitive and straightforward also for biologists who are not used to command-line based software.

An enhancement of the \pkg{opm} package would be to include much more precomputed information about the substrates, thus greatly facilitating data arrangement and hypothesis testing.
At the moment only the translation of well coordinates to substrate names is provided, as well as access to CAS, MeSH, KEGG and Metacyc IDs for the majority of the substrates.
More substrate information could be integrated into the package, particularly for arranging the substrate into groups, thus easing testing of phenotypic hypotheses.

Last but not least, it might also be useful to provide functionality for a direct cross-talk between \pkg{opm} and database management systems.
The current version is entirely file-based, and whereas powerful selection mechanisms for both input files and container objects for previously imported PM plates have already been implemented, future version could directly include database access.
In the meantime, however, the output \proglang{YAML} format (or its subset, \proglang{JSON}) is likely to facilitate the quick establishment of third-party software for importing PM data into a database.

To summarize, we are convinced that the \pkg{opm} package already enables the users to analyse OmniLog\textregistered \ PM data in rather unlimited exploratory directions.


\section[Acknowledgements]{Acknowledgements}

We thank Barry Bochner (BIOLOG Inc.), John Kirkish (BIOLOG Inc.), Andre Chouankam (BIOLOG Inc.), Jan Meier-Kolthoff (DSMZ), Pia W\"{u}st (DSMZ) and Stefan Ehrentraut (DSMZ) for helpful advice, as well as Victoria Michael (DSMZ) for technical support.
We are also grateful to the maintainers of R-Forge and CRAN for providing the online resources used by this project.
This work was supported by the German Research Foundation (DFG) SFB/TRR 51 and by the Microme project within the Framework 7 programme of the European Commission, which is gratefully acknowledged.
JS gratefully acknowledges his support by DFG grant SI 1352/1-2.


\bibliography{opm}

\end{document}

